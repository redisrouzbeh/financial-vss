{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating RAG\n",
    "\n",
    "The extent to which you can **evaluate** your system is the extent to which you can **improve** your system. Before going directly to production then, it is in your best interest to establishing a framework for quickly and effectively understanding the quality of your RAG application. In this notebook, we will use the RAGAS framework as proposed by [this paper](https://arxiv.org/pdf/2309.15217) to evaluate the RAG application developed in the previous examples. \n",
    "\n",
    "There is no substitute for reading the paper, but summarized below are the main metrics we will work with. Note: there are many more metrics that can be used depending on use case but these are the main ones covered in the paper so we will start there. \n",
    "\n",
    "# Quality metric breakdown\n",
    "\n",
    "The 3 quality metrics in the RAGAS framework are: **faithfulness**, **answer relevance**, and **context relevance**. Let's take a moment to define each and understand how we can arrive at their values.\n",
    "\n",
    "## Faithfulness\n",
    "\n",
    "An answer to a question can be said to be \"faithful\" if the **claims** that are made in the answer **can be inferred** from the **context**.\n",
    "\n",
    "The process for quantifying this score is as follows:\n",
    "\n",
    "1. Use the following prompt with an LLM to generate shorter more focused statements provided the question and answer.\n",
    "\n",
    "    > Given a question and answer, create one\n",
    "    > or more statements from each sentence\n",
    "    > in the given answer.\n",
    "    > question: [question]\n",
    "    > answer: [answer]\n",
    "\n",
    "2. For each generated statement, verify if it can be inferred from the context with the following prompt.\n",
    "\n",
    "    > Consider the given context and following\n",
    "    > statements, then determine whether they\n",
    "    > are supported by the information present\n",
    "    > in the context. Provide a brief explanation for each statement before arriving\n",
    "    > at the verdict (Yes/No). Provide a final\n",
    "    > verdict for each statement in order at the\n",
    "    > end in the given format. Do not deviate\n",
    "    > from the specified format.\n",
    "    > statement: [statement 1]\n",
    "    > ...\n",
    "    > statement: [statement n]\n",
    "\n",
    "3. The final score can then be calculated Faithfulness = (number of supported statements) / (total number of statements)\n",
    "\n",
    "## Answer Relevance\n",
    "\n",
    "An answer can be said to be relevant if it directly addresses the question (intuitively).\n",
    "\n",
    "The process for quantifying this score is:\n",
    "\n",
    "1. Use an LLM to generate \"hypothetical\" questions to a given answer with the following prompt:\n",
    "\n",
    "    > Generate a question for the given answer.\n",
    "    > answer: [answer]\n",
    "\n",
    "2. Embed the generated \"hypothetical\" questions as vectors.\n",
    "3. Calculate the cosine similarity of the hypothetical questions and the original question, sum those similarities, and divide by n.\n",
    "\n",
    "Expressed computationally: `Answer Relevance = sum(cos_sim((q, q_i) for q_i in n)) / n`\n",
    "\n",
    "## Context Relevance\n",
    "\n",
    "\"The context is considered relevant to the extent that it exclusively contains information that is needed to answer the question.\"\n",
    "\n",
    "The process:\n",
    "\n",
    "1. Use the following LLM prompt to extract a subset of sentences necessary to answer the question. The context is defined as the formatted search result from the vector database.\n",
    "\n",
    "    > Please extract relevant sentences from\n",
    "    > the provided context that can potentially\n",
    "    > help answer the following `{question}`. If no\n",
    "    > relevant sentences are found, or if you\n",
    "    > believe the question cannot be answered\n",
    "    > from the given context, return the phrase\n",
    "    > \"Insufficient Information\". While extracting candidate sentences you’re not allowed to make any changes to sentences\n",
    "    > from given `{context}`.\n",
    "\n",
    "2. Compute the context relevance score = (number of extracted sentences) / (total number of sentences in context)\n",
    "\n",
    "# Let's start coding!\n",
    "\n",
    "## Step 1: load data\n",
    "\n",
    "If you just finished the other examples this may already be done for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:19:41 redisvl.index.index INFO   Index already exists, overwriting.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from redisvl.index import SearchIndex\n",
    "from redisvl.schema import IndexSchema\n",
    "from redis import Redis\n",
    "\n",
    "# init Redis connection\n",
    "# Replace values below with your own if using Redis Cloud instance\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\")\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")\n",
    "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")\n",
    "\n",
    "# If SSL is enabled on the endpoint, use redis:// as the URL prefix\n",
    "REDIS_URL = f\"redis://{REDIS_HOST}:{REDIS_PORT}\"\n",
    "os.environ[\"REDIS_URL\"] = REDIS_URL\n",
    "\n",
    "index_name = 'langchain'\n",
    "prefix = 'chunk'\n",
    "schema = IndexSchema.from_yaml('sec_index.yaml')\n",
    "client = Redis.from_url(REDIS_URL)\n",
    "# create an index from schema and the client\n",
    "index = SearchIndex(schema, client)\n",
    "index.create(overwrite=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m13:24:03\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   Using Redis address from environment variable, REDIS_URL\n",
      "\n",
      "\n",
      "Index Information:\n",
      "╭──────────────┬────────────────┬────────────┬─────────────────┬────────────╮\n",
      "│ Index Name   │ Storage Type   │ Prefixes   │ Index Options   │   Indexing │\n",
      "├──────────────┼────────────────┼────────────┼─────────────────┼────────────┤\n",
      "│ langchain    │ HASH           │ ['chunk']  │ []              │          0 │\n",
      "╰──────────────┴────────────────┴────────────┴─────────────────┴────────────╯\n",
      "Index Fields:\n",
      "╭────────────────┬────────────────┬─────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬─────────────────┬────────────────╮\n",
      "│ Name           │ Attribute      │ Type    │ Field Option   │ Option Value   │ Field Option   │ Option Value   │ Field Option   │   Option Value │ Field Option    │ Option Value   │\n",
      "├────────────────┼────────────────┼─────────┼────────────────┼────────────────┼────────────────┼────────────────┼────────────────┼────────────────┼─────────────────┼────────────────┤\n",
      "│ chunk_id       │ chunk_id       │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ source_doc     │ source_doc     │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ doc_type       │ doc_type       │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ content        │ content        │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ ticker         │ ticker         │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ company_name   │ company_name   │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ sector         │ sector         │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ asset_class    │ asset_class    │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ location       │ location       │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ exchange       │ exchange       │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ currency       │ currency       │ TAG     │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ market_value   │ market_value   │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
      "│ weight         │ weight         │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
      "│ notional_value │ notional_value │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
      "│ shares         │ shares         │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
      "│ price          │ price          │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
      "│ text_embedding │ text_embedding │ VECTOR  │ algorithm      │ FLAT           │ data_type      │ FLOAT32        │ dim            │            384 │ distance_metric │ COSINE         │\n",
      "╰────────────────┴────────────────┴─────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴─────────────────┴────────────────╯\n"
     ]
    }
   ],
   "source": [
    "# check index was created properly\n",
    "!rvl index info -i langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure env\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dir_path = os.getcwd()\n",
    "parent_directory = os.path.dirname(dir_path)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"ROOT_DIR\"] = parent_directory\n",
    "# print(dir_path)\n",
    "# print(parent_directory)\n",
    "\n",
    "#setting the local downloaded sentence transformer models f\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = f\"{parent_directory}/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/Documents/boa/financial-vss/multi_doc_RAG\n",
      "/Users/robert.shelton/Documents/boa/financial-vss\n",
      " ✅ Loaded doc info for  110 tickers...\n",
      "✅ Loaded 108 10K chunks for ticker=AAPL from AAPL-2021-10K.pdf\n",
      "✅ Loaded 94 10K chunks for ticker=AAPL from AAPL-2023-10K.pdf\n",
      "✅ Loaded 103 10K chunks for ticker=AAPL from AAPL-2022-10K.pdf\n",
      "✅ Loaded 27 earning_call chunks for ticker=AAPL from 2018-May-01-AAPL.txt\n",
      "✅ Loaded 31 earning_call chunks for ticker=AAPL from 2019-Oct-30-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2016-Jan-26-AAPL.txt\n",
      "✅ Loaded 31 earning_call chunks for ticker=AAPL from 2020-Jul-30-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2017-Aug-01-AAPL.txt\n",
      "✅ Loaded 29 earning_call chunks for ticker=AAPL from 2020-Jan-28-AAPL.txt\n",
      "✅ Loaded 34 earning_call chunks for ticker=AAPL from 2016-Apr-26-AAPL.txt\n",
      "✅ Loaded 29 earning_call chunks for ticker=AAPL from 2017-Jan-31-AAPL.txt\n",
      "✅ Loaded 28 earning_call chunks for ticker=AAPL from 2019-Apr-30-AAPL.txt\n",
      "✅ Loaded 26 earning_call chunks for ticker=AAPL from 2017-Nov-02-AAPL.txt\n",
      "✅ Loaded 31 earning_call chunks for ticker=AAPL from 2016-Oct-25-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2016-Jul-26-AAPL.txt\n",
      "✅ Loaded 27 earning_call chunks for ticker=AAPL from 2017-May-02-AAPL.txt\n",
      "✅ Loaded 32 earning_call chunks for ticker=AAPL from 2019-Jul-30-AAPL.txt\n",
      "✅ Loaded 31 earning_call chunks for ticker=AAPL from 2019-Jan-29-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2018-Jul-31-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2018-Feb-01-AAPL.txt\n",
      "✅ Loaded 33 earning_call chunks for ticker=AAPL from 2018-Nov-01-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2020-Apr-30-AAPL.txt\n",
      "✅ Loaded 125 10K chunks for ticker=AMZN from AMZN-2023-10K.pdf\n",
      "✅ Loaded 117 10K chunks for ticker=AMZN from AMZN-2022-10K.pdf\n",
      "✅ Loaded 118 10K chunks for ticker=AMZN from AMZN-2021-10K.pdf\n",
      "✅ Loaded 20 earning_call chunks for ticker=AMZN from 2020-Jan-30-AMZN.txt\n",
      "✅ Loaded 28 earning_call chunks for ticker=AMZN from 2016-Apr-28-AMZN.txt\n",
      "✅ Loaded 19 earning_call chunks for ticker=AMZN from 2019-Oct-24-AMZN.txt\n",
      "✅ Loaded 24 earning_call chunks for ticker=AMZN from 2020-Apr-30-AMZN.txt\n",
      "✅ Loaded 22 earning_call chunks for ticker=AMZN from 2019-Apr-25-AMZN.txt\n",
      "✅ Loaded 17 earning_call chunks for ticker=AMZN from 2017-Jul-27-AMZN.txt\n",
      "✅ Loaded 20 earning_call chunks for ticker=AMZN from 2018-Jul-26-AMZN.txt\n",
      "✅ Loaded 20 earning_call chunks for ticker=AMZN from 2018-Oct-25-AMZN.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AMZN from 2016-Jan-28-AMZN.txt\n",
      "✅ Loaded 21 earning_call chunks for ticker=AMZN from 2018-Feb-01-AMZN.txt\n",
      "✅ Loaded 23 earning_call chunks for ticker=AMZN from 2020-Jul-30-AMZN.txt\n",
      "✅ Loaded 21 earning_call chunks for ticker=AMZN from 2019-Jul-25-AMZN.txt\n",
      "✅ Loaded 21 earning_call chunks for ticker=AMZN from 2017-Apr-27-AMZN.txt\n",
      "✅ Loaded 20 earning_call chunks for ticker=AMZN from 2019-Jan-31-AMZN.txt\n",
      "✅ Loaded 19 earning_call chunks for ticker=AMZN from 2018-Apr-26-AMZN.txt\n",
      "✅ Loaded 22 earning_call chunks for ticker=AMZN from 2016-Oct-27-AMZN.txt\n",
      "✅ Loaded 21 earning_call chunks for ticker=AMZN from 2017-Feb-02-AMZN.txt\n",
      "✅ Loaded 26 earning_call chunks for ticker=AMZN from 2016-Jul-28-AMZN.txt\n",
      "✅ Loaded 19 earning_call chunks for ticker=AMZN from 2017-Oct-26-AMZN.txt\n",
      "✅✅✅Loaded a total of 1647 chunks from 6 10Ks and 38 earning calls for 2 tickers.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings \n",
    "from ingestion import get_sec_data\n",
    "from ingestion import redis_bulk_upload\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", cache_folder=os.getenv(\"TRANSFORMERS_CACHE\", f\"{parent_directory}/models\"))\n",
    "sec_data = get_sec_data()\n",
    "chunks = redis_bulk_upload(sec_data, index, embeddings, tickers=['AAPL', 'AMZN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate index and create vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Redis as LangChainRedis\n",
    "from utils import create_langchain_schemas_from_redis_schema\n",
    "\n",
    "index_name = 'langchain'\n",
    "\n",
    "vec_schema , main_schema = create_langchain_schemas_from_redis_schema('sec_index.yaml')\n",
    "\n",
    "rds = LangChainRedis.from_existing_index( embedding=embeddings, \n",
    "                                          index_name= index_name, \n",
    "                                          schema = main_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds.similarity_search(\"What was apples revenue last year?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Setup RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use openai to get unblocked then get ollama going\n",
    "# this might need to change but later thought\n",
    "# import openai\n",
    "# import os\n",
    "# import getpass\n",
    "# from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "# CHAT_MODEL = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "# if \"OPENAI_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt():\n",
    "    \"\"\"Create the QA chain.\"\"\"\n",
    "    from langchain.prompts import PromptTemplate\n",
    "\n",
    "    # Define our prompt\n",
    "    prompt_template = \"\"\"Use the following pieces of context from financial 10k filings data to answer the user question at the end. Only use the result from tools and evidence provided to you. If you don't know the answer, say that you don't know, don't try to make up an answer. Provide the source of the document that you used to get the answer.\n",
    "\n",
    "    This should be in the following format:\n",
    "\n",
    "    Question: [question here]\n",
    "    Answer: [answer here]\n",
    "    Source: [source document here]\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Context:\n",
    "    ---------\n",
    "    {context}\n",
    "    ---------\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def get_search_kwargs(filters, distance_threshold):\n",
    "    return {\"distance_threshold\":distance_threshold,\"filter\":filters}\n",
    "    \n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=rds.as_retriever(search_type=\"similarity_distance_threshold\",\n",
    "                               search_kwargs={\"distance_threshold\":0.8, 'include_metadata': True}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': \"What was Apple's revenue last year compared to this year??\",\n",
       " 'result': \"Question: What was Apple's revenue last year compared to this year??\\nAnswer: In fiscal year '18, our revenue grew by $36.4 billion.\\nSource: https://www.sec.gov/Archives/edgar/data/99662/000119312018061311/d551511d10k.htm (Apple Inc.'s 10-K filing for 2018)\",\n",
       " 'source_documents': [Document(page_content=\"revenue and earnings in Apple's history. In fiscal year '18, our revenue grew by $36.4 billion. That's the equivalent of a Fortune 100 company in a single year. And we're capping all that off with our best September quarter ever. Revenue was $62.9 billion, ahead of our expectations. That's an increase of 20% over last year and our highest growth rate in 3 years. We also generated record Q4\", metadata={'id': 'chunk:2018-Nov-01-AAPL.txt-c7764e65-9866-4559-a1b7-8baa72e6b733', 'chunk_id': '2018-Nov-01-AAPL.txt-c7764e65-9866-4559-a1b7-8baa72e6b733', 'source_doc': '2018-Nov-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content=\"revenue and earnings in Apple's history. In fiscal year '18, our revenue grew by $36.4 billion. That's the equivalent of a Fortune 100 company in a single year. And we're capping all that off with our best September quarter ever. Revenue was $62.9 billion, ahead of our expectations. That's an increase of 20% over last year and our highest growth rate in 3 years. We also generated record Q4\", metadata={'id': 'chunk:2018-Nov-01-AAPL.txt-b812d887-2f7f-496e-a23c-604b0a41216c', 'chunk_id': '2018-Nov-01-AAPL.txt-b812d887-2f7f-496e-a23c-604b0a41216c', 'source_doc': '2018-Nov-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content='Mac: 1. Revenue $7.1b; June qtr. record. 1. Up 22% YoverY. 2. Grew double-digits in each geographic segment. 3. Set all-time revenue records in Japan and rest of Asia-Pacific and June qtr. records in Americas and Europe. 2. Customer response to new MacBook Air and MacBook Pro launches has been strong. 2. iPad: 1. Revenue $6.6b, up 31%. 1. Highest June qtr. revenue in eight years. 2. Demand was', metadata={'id': 'chunk:2020-Jul-30-AAPL.txt-0aa0805c-df77-4559-b40e-f435cf2661c1', 'chunk_id': '2020-Jul-30-AAPL.txt-0aa0805c-df77-4559-b40e-f435cf2661c1', 'source_doc': '2020-Jul-30-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content='Mac: 1. Revenue $7.1b; June qtr. record. 1. Up 22% YoverY. 2. Grew double-digits in each geographic segment. 3. Set all-time revenue records in Japan and rest of Asia-Pacific and June qtr. records in Americas and Europe. 2. Customer response to new MacBook Air and MacBook Pro launches has been strong. 2. iPad: 1. Revenue $6.6b, up 31%. 1. Highest June qtr. revenue in eight years. 2. Demand was', metadata={'id': 'chunk:2020-Jul-30-AAPL.txt-23ac1f3d-f26a-45ed-ae4e-390596bf7170', 'chunk_id': '2020-Jul-30-AAPL.txt-23ac1f3d-f26a-45ed-ae4e-390596bf7170', 'source_doc': '2020-Jul-30-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What was Apple's revenue last year compared to this year??\"\n",
    "res=qa(query)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What was Apple's revenue last year compared to this year??\",\n",
       " 'result': \"Question: What was Apple's revenue last year compared to this year??\\nAnswer: According to the text, in fiscal year '18, Apple's revenue grew by $36.4 billion. This means that their revenue increased from the previous year.\\n\\nSource: Apple's 10-K filing for FY2018 (not provided, but based on the text)\",\n",
       " 'source_documents': [Document(page_content=\"Thank you, Nancy. Good afternoon, everyone, and thanks for joining us. I just got back from Brooklyn, where we marked our fourth major launch at the end of the year. In addition to being a great time, it put an exclamation point at the end of a remarkable fiscal 2018. This year, we shipped our 2 billionth iOS device, celebrated the 10th anniversary of the App Store and achieved the strongest revenue and earnings in Apple's history. In fiscal year '18, our revenue grew by $36.4 billion. That's the equivalent of a Fortune 100 company in a single year. And we're capping all that off with our best September quarter ever. Revenue was $62.9 billion, ahead of our expectations. That's an increase of 20% over last year and our highest growth rate in 3 years. We also generated record Q4 earnings with 41% year-over-year growth in EPS. Record results from iPhone, Services and Wearables drove our momentum, and we produced strong double-digit revenue growth in all of our geographic segments. It was a big year and a big quarter for iPhone. Q4 revenue was up 29% over last year, an increase of over $8 billion to a new September quarter record, fueled by continued momentum for iPhone 8, 8 Plus and X and the very successful launch of iPhone Xs and iPhone Xs Max. These latest devices are our most advanced iPhones ever with the industry's first 7-nanometer A12 Bionic chip with an Apple-designed 8-core Neural Engine capable of executing an astounding 5 trillion operations per second.\", metadata={'id': 'chunk:2018-Nov-01-AAPL.txt-ea8e3024-e71b-4f72-968d-4255f2191ad6', 'chunk_id': '2018-Nov-01-AAPL.txt-ea8e3024-e71b-4f72-968d-4255f2191ad6', 'source_doc': '2018-Nov-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content=\"According to App Annie's latest report, App Store continues to build preferred destination for customer purchases by wide margin, generating nearly twice revenue of Google Play. 3. Across all Services offerings, paid subscriptions reached 240m, with growth of 58% over last year. 1. Major contributor to overall strong growth in revenue. 4. Apple Watch: 1. Best qtr. ever. 2. Adding results from Beats and AirPods, total revenue from wearables up almost 70% YoverY. 3. Wearables second largest contributor to revenue growth after iPhone. 1. Started only three years ago. 4. In total, other products category set new all-time record with quarterly revenue exceeding $5b for first time. 5. Mac: 1. Sold 5.1m Macs. 1. Translates to 2% YoverY increase in avg. sales per week. 2. Performance particularly strong in emerging markets with unit sales up 13% YoverY and with all-time records in Latin America, India, Turkey and Central and Eastern Europe. 3. Worldwide, active installed base of Macs up double digits YoverY to new record. 6. iPad: 1. Growth qtr. 2. Sold 13.2m units. 1. Avg. iPad sales per week [up 8%] over last year's Dec. qtr. 3. Sales grew strong double digits in many emerging markets including Latin America, Middle East, Central and Eastern Europe and India, and developed markets including Japan, Australia and Korea. 4. Active installed base of iPad has grown every qtr. since launch in 2010. 1.\", metadata={'id': 'chunk:2018-Feb-01-AAPL.txt-2e242c28-73e6-4664-ab69-518899d77ff6', 'chunk_id': '2018-Feb-01-AAPL.txt-2e242c28-73e6-4664-ab69-518899d77ff6', 'source_doc': '2018-Feb-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content=\"Earlier this month, released macOS Catalina with all new entertainment apps, innovative Sidecar feature that uses iPad to expand Mac workspace and new accessibility tools that enable users to control their Mac entirely with their voice. 1. Catalina brings Apple Arcade experience to Mac. 1. Already seeing some third-party developers bring their iPad apps to Mac App Store with Mac Catalyst, including Twitter, Post-it and more. 4. Launching newly redesigned Mac Pro this fall, which Co. is manufacturing in Austin, Texas. 7. Others: 1. In FY19, crossed $100b in revenue in US for first time. 2. Introduce new services from Apple Card to Apple TV+ and generated over $46b in total Services revenue, setting new yearly Services records in all five geographic segments and driving Services business to size of Fortune 70 co. 3. Delivered new hardware in all device categories. 4. Wearables business showed explosive growth and generated more annual revenue than two-thirds of companies in Fortune 500. 5. Set yearly revenue record for Mac. 6. Outside of iPhone, revenue grew by $17b to almost $118b. 7. Overall success was achieved widely across markets with annual revenue records in US, Canada, Brazil, UK, Germany, France, Italy, Poland, Korea, Malaysia, Philippines and Vietnam. 8. Believes that Co. leads in innovation because AAPL leads with its values. 9.\\n\\nAt time of urgency and action on climate change, continues to drive breakthroughs in clean power, sustainable materials and device recycling. 1. By running 100% of global operations on renewable energy and challenging entire network of suppliers do the same, Co. is driving virtuous cycle of demand for clean sources of power. 2. Sees award Co. recently received from United Nation's Global Climate Action program as mandate to deepen this vital work. 10. Continues to invent and improves on cutting-edge renewable materials, including 100% recycled aluminum alloy found in many of Co.'s products. 1. Added rare earth elements to list of recycled materials with introduction of iPhone 11. 2. Disassembling, recycling or refurbishing millions of devices every year with help of Daisy, recycling robot, and pushing entire global supply chain toward recycled or renewable materials. 11. Driving access to critical coding skills development to educators and students through programs like teaching coding academies and free Everyone Can Code curriculum. 12. Continues to put user privacy at center of everything that Co. does.\", metadata={'id': 'chunk:2019-Oct-30-AAPL.txt-3b4d6967-1478-4434-a875-ed38ff74fdd0', 'chunk_id': '2019-Oct-30-AAPL.txt-3b4d6967-1478-4434-a875-ed38ff74fdd0', 'source_doc': '2019-Oct-30-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content='Revenue almost $6.1b, including $548m received from patent infringement dispute. 1. Excluding that amount, revenue was $5.5b. 1. New all-time record and increase of 15% over last year due in large part to strong growth from apps. 2. Revenue from App Store increased 27%. 1. Number of transacting customers grew 18%; all-time record. 3. Among customers who purchase apps and content from iTunes Stores, avg. amount spent for customer reached an all-time high in Dec. qtr. 8. Other Details: 1. Revenue from other products grew strongly. 1. Up 62% YoverY due to: 1. Growing contribution from Apple Watch. 2. Successful launch of new Apple TV. 2. Both aforementioned established new all-time quarterly records. 2. Expanded Apple Watch distribution significantly over course of qtr. 1. Experienced especially strong results during holiday buying season. 9. Cash Position: 1. 1Q16-end [$215.7b] in cash plus marketable securities. 1. Increased $10.1b sequentially. 2. $200b of this cash or 93% of total was outside US. 2. Returned over $9b to investors. 3. Paid $3b in dividends and equivalents. 4. Spent $3b to repurchase 26m AAPL shares through open market transactions. 5. Launched sixth share repurchase program, spending $3b and receiving an initial delivery of [20.4m shares]. 6. Now completed over $153b of our $200b program, including $110b in share purchases. 7. Plans to provide update on capital return program during 2Q results in April. 1.\\n\\nPlans to be active in US and international debt markets in 2016 in order to fund capital return activities. 2. On 01/26/16, Board of Directors declared cash dividend of $0.52 per share of common stock payable on 02/11/16 to shareholders of record as of 02/08/16. 10. 2Q16 Guidance: 1. Revenue $50-53b. 1. Providing wider range for revenue than usual for 2Q because of volatility seeing in economy and financial and currency markets. 2. GM 39.0-39.5%. 1. Believes these are extremely strong margins in light of headwinds faced from FX and sequential loss of leverage. 3. OpEx $6.0-6.1b. 4. OI&E about $325m. 5. Tax rate about 25.5%. 6. Does not provide guidance beyond current qtr. 1. Difficult to forecast economic and FX factors. 2. At this point, believes March qtr. faces most difficult YoverY compare relative to rest of year.', metadata={'id': 'chunk:2016-Jan-26-AAPL.txt-070e9c42-a156-480c-95e9-68a7cdb89be0', 'chunk_id': '2016-Jan-26-AAPL.txt-070e9c42-a156-480c-95e9-68a7cdb89be0', 'source_doc': '2016-Jan-26-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's generate a test data set\n",
    "\n",
    "We will use the convenient TestSetGenerator class from the ragas package to help us quickly get started evaluating our apps. The generator class will take our documents as input and use an LLM to generate feasible questions from our dataset based on slices of context and the critic LLM to extract ground truth data to be measured against.\n",
    "\n",
    "Note: this methodology has been shown to be effective when creating one's own human labeled test set is not pragmatic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_chunks = [item for sublist in chunks for item in sublist]\n",
    "assert len(flattened_chunks) > len(chunks)\n",
    "flattened_chunks_sample = flattened_chunks[:100] + flattened_chunks[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549\\n\\nFORM 10-K\\n\\n(Mark One)\\n\\n☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the fiscal year ended September 25, 2021 or ☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\n\\nFor the transition period from to .\\n\\nCommission File Number: 001-36743\\n\\nApple Inc.\\n\\n(Exact name of Registrant as specified in its charter)\\n\\nCalifornia (State or other jurisdiction of incorporation or organization)\\n\\n94-2404110 (I.R.S. Employer Identification No.)\\n\\nOne Apple Park Way Cupertino, California (Address of principal executive offices)\\n\\n95014 (Zip Code)\\n\\n(408) 996-1010 (Registrant’s telephone number, including area code)\\n\\nSecurities registered pursuant to Section 12(b) of the Act:\\n\\nTitle of each class Common Stock, $0.00001 par value per share\\n\\n1.000% Notes due 2022 1.375% Notes due 2024 0.000% Notes due 2025 0.875% Notes due 2025 1.625% Notes due 2026 2.000% Notes due 2027 1.375% Notes due 2029 3.050% Notes due 2029 0.500% Notes due 2031 3.600% Notes due 2042\\n\\nTrading symbol(s) AAPL — — — — — — — — — —\\n\\nName of each exchange on which registered The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC\\n\\nSecurities registered pursuant to Section 12(g) of the Act: None\\n\\nIndicate by check mark if the Registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.\\n\\nYes ☒ No ☐\\n\\nIndicate by check mark if the Registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act.\\n\\nYes ☐ No ☒\\n\\nIndicate by check mark whether the Registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the Registrant was required to file such reports), and (2) has been subject to\\n\\nsuch filing requirements for the past 90 days.\\n\\nYes ☒ No ☐'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_chunks_sample[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866d4ad8b7f64d2c8f7c1426f9c50699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe170090f7f4685aa4569ecc420b715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will use the testset generator from RAGAS to being our evaluation\n",
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# generator with openai models\n",
    "generator_llm = Ollama(model=\"llama3\")\n",
    "critic_llm = Ollama(model=\"llama3\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings,\n",
    ")\n",
    "\n",
    "\n",
    "testset_sample = generator.generate_with_langchain_docs(flattened_chunks_sample, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of incorporating portions ...</td>\n",
       "      <td>[Portions of the Registrant’s definitive proxy...</td>\n",
       "      <td>The purpose of incorporating portions of the R...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What factors should users review before making...</td>\n",
       "      <td>[THE INFORMATION CONTAINED IN EVENT TRANSCRIPT...</td>\n",
       "      <td>The applicable company's conference call itsel...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does competition in the market affect the ...</td>\n",
       "      <td>[The Company’s ability to compete successfully...</td>\n",
       "      <td>Competition in the market can affect the suppl...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the purpose of the Investor Relations ...</td>\n",
       "      <td>[---------------------------------------------...</td>\n",
       "      <td>The purpose of the Investor Relations departme...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Amazon's approach to investment levels...</td>\n",
       "      <td>[---------------------------------------------...</td>\n",
       "      <td>We continue to invest heavily on behalf of cus...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does the determination of the discount rat...</td>\n",
       "      <td>[The discount rate related to the Company’s le...</td>\n",
       "      <td>The discount rate for lease liabilities is gen...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What intellectual property rights does the Com...</td>\n",
       "      <td>[The Company currently holds a broad collectio...</td>\n",
       "      <td>The Company holds a broad collection of intell...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the risks and consequences of using a...</td>\n",
       "      <td>[The Company and its global supply chain are e...</td>\n",
       "      <td>Losses or unauthorized access to or releases o...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What are the obligations and requirements for ...</td>\n",
       "      <td>[In addition to the risks generally relating t...</td>\n",
       "      <td>Financial data, such as payment card data, is ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do trade restrictions and tariffs impact t...</td>\n",
       "      <td>[The Company has a large, global business, and...</td>\n",
       "      <td>Trade restrictions and tariffs can impact the ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': '/Users/robert.shelton/Documents/b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the purpose of incorporating portions ...   \n",
       "1  What factors should users review before making...   \n",
       "2  How does competition in the market affect the ...   \n",
       "3  What is the purpose of the Investor Relations ...   \n",
       "4  What is Amazon's approach to investment levels...   \n",
       "5  How does the determination of the discount rat...   \n",
       "6  What intellectual property rights does the Com...   \n",
       "7  What are the risks and consequences of using a...   \n",
       "8  What are the obligations and requirements for ...   \n",
       "9  How do trade restrictions and tariffs impact t...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Portions of the Registrant’s definitive proxy...   \n",
       "1  [THE INFORMATION CONTAINED IN EVENT TRANSCRIPT...   \n",
       "2  [The Company’s ability to compete successfully...   \n",
       "3  [---------------------------------------------...   \n",
       "4  [---------------------------------------------...   \n",
       "5  [The discount rate related to the Company’s le...   \n",
       "6  [The Company currently holds a broad collectio...   \n",
       "7  [The Company and its global supply chain are e...   \n",
       "8  [In addition to the risks generally relating t...   \n",
       "9  [The Company has a large, global business, and...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The purpose of incorporating portions of the R...         simple   \n",
       "1  The applicable company's conference call itsel...         simple   \n",
       "2  Competition in the market can affect the suppl...         simple   \n",
       "3  The purpose of the Investor Relations departme...         simple   \n",
       "4  We continue to invest heavily on behalf of cus...         simple   \n",
       "5  The discount rate for lease liabilities is gen...      reasoning   \n",
       "6  The Company holds a broad collection of intell...      reasoning   \n",
       "7  Losses or unauthorized access to or releases o...  multi_context   \n",
       "8  Financial data, such as payment card data, is ...  multi_context   \n",
       "9  Trade restrictions and tariffs can impact the ...  multi_context   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "1  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "2  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "3  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "4  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "5  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "6  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "7  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "8  [{'source': '/Users/robert.shelton/Documents/b...          True  \n",
       "9  [{'source': '/Users/robert.shelton/Documents/b...          True  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_sample.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reusable helper function for evaluating our test set against different chains\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_relevancy,\n",
    ")\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "def parse_contexts(source_docs):\n",
    "    return [doc.page_content for doc in source_docs]\n",
    "\n",
    "def create_evaluation_dataset(chain, testset_df):\n",
    "    res_set = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": [],\n",
    "        \"ground_truth\": []\n",
    "    }\n",
    "\n",
    "    for test in testset_df.iterrows():\n",
    "        query = test[1][\"question\"]\n",
    "        result = chain(query)\n",
    "\n",
    "        res_set[\"question\"].append(query)\n",
    "        res_set[\"answer\"].append(result[\"result\"])\n",
    "        res_set[\"contexts\"].append(parse_contexts(result[\"source_documents\"]))\n",
    "        res_set[\"ground_truth\"].append(test[1][\"ground_truth\"])\n",
    "    return Dataset.from_dict(res_set)\n",
    "\n",
    "def evaluate_chain(chain, testset_df, test_name):\n",
    "    eval_dataset = create_evaluation_dataset(chain, testset_df)\n",
    "\n",
    "    eval_result = evaluate(\n",
    "        eval_dataset,\n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_relevancy\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    eval_df = eval_result.to_pandas()\n",
    "    eval_df.to_csv(f\"{test_name}.csv\")\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f22983684a4758a3add780bc61c4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_rag_eval = evaluate_chain(qa, testset_sample.to_pandas(), \"basic_rag_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.988599</td>\n",
       "      <td>0.045145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.253914</td>\n",
       "      <td>0.036051</td>\n",
       "      <td>0.039301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.885996</td>\n",
       "      <td>0.005236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.016296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy  context_relevancy\n",
       "count     10.000000         10.000000          10.000000\n",
       "mean       0.865000          0.988599           0.045145\n",
       "std        0.253914          0.036051           0.039301\n",
       "min        0.250000          0.885996           0.005236\n",
       "25%        0.850000          0.999999           0.016296\n",
       "50%        1.000000          1.000000           0.034722\n",
       "75%        1.000000          1.000000           0.068509\n",
       "max        1.000000          1.000000           0.130435"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_rag_eval.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis \n",
    "\n",
    "From the above we can see that we did okay in terms of faithfulness and answer relevancy but our context relevancy is not very good at all. This means we are passing a bunch of unnecessary context to our LLM. As an example, we could improve this using Parent Document Retriever to help fine tune our input data. \n",
    "\n",
    "To test this we will setup a similar RAG system but replace the retriever we used earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:23:14 redisvl.index.index INFO   Index already exists, overwriting.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Redis as LangChainRedis\n",
    "from utils import create_langchain_schemas_from_redis_schema\n",
    "\n",
    "index_name = 'parent_doc_sec'\n",
    "schema = IndexSchema.from_yaml('parent_doc_sec.yaml')\n",
    "client = Redis.from_url(REDIS_URL)\n",
    "# create an index from schema and the client\n",
    "index = SearchIndex(schema, client)\n",
    "index.create(overwrite=True, drop=True)\n",
    "\n",
    "vec_schema , main_schema = create_langchain_schemas_from_redis_schema('parent_doc_sec.yaml')\n",
    "\n",
    "rds = LangChainRedis.from_existing_index( embedding=embeddings, \n",
    "                                          index_name= index_name, \n",
    "                                          schema = main_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/Documents/boa/financial-vss/multi_doc_RAG\n",
      "/Users/robert.shelton/Documents/boa/financial-vss\n"
     ]
    }
   ],
   "source": [
    "from ingestion import redis_bulk_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vector': [{'name': 'text_embedding',\n",
       "   'algorithm': 'FLAT',\n",
       "   'dims': 384,\n",
       "   'distance_metric': 'COSINE',\n",
       "   'datatype': 'FLOAT32'}],\n",
       " 'text': [{'name': 'content'}],\n",
       " 'tag': [{'name': 'chunk_id'},\n",
       "  {'name': 'source_doc'},\n",
       "  {'name': 'doc_type'},\n",
       "  {'name': 'ticker'},\n",
       "  {'name': 'company_name'},\n",
       "  {'name': 'sector'},\n",
       "  {'name': 'asset_class'},\n",
       "  {'name': 'location'},\n",
       "  {'name': 'exchange'},\n",
       "  {'name': 'currency'}],\n",
       " 'numeric': [{'name': 'market_value'},\n",
       "  {'name': 'weight'},\n",
       "  {'name': 'notional_value'},\n",
       "  {'name': 'shares'},\n",
       "  {'name': 'price'}],\n",
       " 'content_vector_key': 'text_embedding'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Loaded doc info for  110 tickers...\n",
      "✅ Loaded 779 10K chunks for ticker=AAPL from AAPL-2021-10K.pdf\n",
      "✅ Loaded 689 10K chunks for ticker=AAPL from AAPL-2023-10K.pdf\n",
      "✅ Loaded 748 10K chunks for ticker=AAPL from AAPL-2022-10K.pdf\n",
      "✅ Loaded 155 earning_call chunks for ticker=AAPL from 2018-May-01-AAPL.txt\n",
      "✅ Loaded 193 earning_call chunks for ticker=AAPL from 2019-Oct-30-AAPL.txt\n",
      "✅ Loaded 200 earning_call chunks for ticker=AAPL from 2016-Jan-26-AAPL.txt\n",
      "✅ Loaded 196 earning_call chunks for ticker=AAPL from 2020-Jul-30-AAPL.txt\n",
      "✅ Loaded 176 earning_call chunks for ticker=AAPL from 2017-Aug-01-AAPL.txt\n",
      "✅ Loaded 179 earning_call chunks for ticker=AAPL from 2020-Jan-28-AAPL.txt\n",
      "✅ Loaded 209 earning_call chunks for ticker=AAPL from 2016-Apr-26-AAPL.txt\n",
      "✅ Loaded 177 earning_call chunks for ticker=AAPL from 2017-Jan-31-AAPL.txt\n",
      "✅ Loaded 176 earning_call chunks for ticker=AAPL from 2019-Apr-30-AAPL.txt\n",
      "✅ Loaded 155 earning_call chunks for ticker=AAPL from 2017-Nov-02-AAPL.txt\n",
      "✅ Loaded 189 earning_call chunks for ticker=AAPL from 2016-Oct-25-AAPL.txt\n",
      "✅ Loaded 173 earning_call chunks for ticker=AAPL from 2016-Jul-26-AAPL.txt\n",
      "✅ Loaded 175 earning_call chunks for ticker=AAPL from 2017-May-02-AAPL.txt\n",
      "✅ Loaded 192 earning_call chunks for ticker=AAPL from 2019-Jul-30-AAPL.txt\n",
      "✅ Loaded 171 earning_call chunks for ticker=AAPL from 2019-Jan-29-AAPL.txt\n",
      "✅ Loaded 173 earning_call chunks for ticker=AAPL from 2018-Jul-31-AAPL.txt\n",
      "✅ Loaded 192 earning_call chunks for ticker=AAPL from 2018-Feb-01-AAPL.txt\n",
      "✅ Loaded 180 earning_call chunks for ticker=AAPL from 2018-Nov-01-AAPL.txt\n",
      "✅ Loaded 189 earning_call chunks for ticker=AAPL from 2020-Apr-30-AAPL.txt\n",
      "✅ Loaded 905 10K chunks for ticker=AMZN from AMZN-2023-10K.pdf\n",
      "✅ Loaded 864 10K chunks for ticker=AMZN from AMZN-2022-10K.pdf\n",
      "✅ Loaded 873 10K chunks for ticker=AMZN from AMZN-2021-10K.pdf\n",
      "✅ Loaded 141 earning_call chunks for ticker=AMZN from 2020-Jan-30-AMZN.txt\n",
      "✅ Loaded 202 earning_call chunks for ticker=AMZN from 2016-Apr-28-AMZN.txt\n",
      "✅ Loaded 130 earning_call chunks for ticker=AMZN from 2019-Oct-24-AMZN.txt\n",
      "✅ Loaded 138 earning_call chunks for ticker=AMZN from 2020-Apr-30-AMZN.txt\n",
      "✅ Loaded 147 earning_call chunks for ticker=AMZN from 2019-Apr-25-AMZN.txt\n",
      "✅ Loaded 124 earning_call chunks for ticker=AMZN from 2017-Jul-27-AMZN.txt\n",
      "✅ Loaded 130 earning_call chunks for ticker=AMZN from 2018-Jul-26-AMZN.txt\n",
      "✅ Loaded 135 earning_call chunks for ticker=AMZN from 2018-Oct-25-AMZN.txt\n",
      "✅ Loaded 210 earning_call chunks for ticker=AMZN from 2016-Jan-28-AMZN.txt\n",
      "✅ Loaded 138 earning_call chunks for ticker=AMZN from 2018-Feb-01-AMZN.txt\n",
      "✅ Loaded 144 earning_call chunks for ticker=AMZN from 2020-Jul-30-AMZN.txt\n",
      "✅ Loaded 143 earning_call chunks for ticker=AMZN from 2019-Jul-25-AMZN.txt\n",
      "✅ Loaded 155 earning_call chunks for ticker=AMZN from 2017-Apr-27-AMZN.txt\n",
      "✅ Loaded 147 earning_call chunks for ticker=AMZN from 2019-Jan-31-AMZN.txt\n",
      "✅ Loaded 137 earning_call chunks for ticker=AMZN from 2018-Apr-26-AMZN.txt\n",
      "✅ Loaded 135 earning_call chunks for ticker=AMZN from 2016-Oct-27-AMZN.txt\n",
      "✅ Loaded 152 earning_call chunks for ticker=AMZN from 2017-Feb-02-AMZN.txt\n",
      "✅ Loaded 161 earning_call chunks for ticker=AMZN from 2016-Jul-28-AMZN.txt\n",
      "✅ Loaded 146 earning_call chunks for ticker=AMZN from 2017-Oct-26-AMZN.txt\n",
      "✅✅✅Loaded a total of 11123 chunks from 6 10Ks and 38 earning calls for 2 tickers.\n"
     ]
    }
   ],
   "source": [
    "from ingestion import get_sec_data\n",
    "from ingestion import redis_bulk_upload\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "child_chunk_size=400\n",
    "parent_chunk_size=2000\n",
    "\n",
    "# This text splitter is used to create the parent documents\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=parent_chunk_size)\n",
    "# This text splitter is used to create the child documents\n",
    "# It should create documents smaller than the parent\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=child_chunk_size)\n",
    "\n",
    "sec_data = get_sec_data()\n",
    "child_chunks = redis_bulk_upload(sec_data, index, embeddings, chunk_size=child_chunk_size, tickers=['AAPL', 'AMZN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_chunks = [item for sublist in child_chunks for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LocalFileStore.__init__() missing 1 required positional argument: 'root_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lc_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_kv_docstore\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# The storage layer for the parent documents\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# store = InMemoryStore()\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m fs \u001b[38;5;241m=\u001b[39m \u001b[43mLocalFileStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m store \u001b[38;5;241m=\u001b[39m create_kv_docstore(fs)\n\u001b[1;32m     10\u001b[0m parent_doc_vector_store \u001b[38;5;241m=\u001b[39m LangChainRedis\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[1;32m     11\u001b[0m     documents\u001b[38;5;241m=\u001b[39mflattened_chunks,\n\u001b[1;32m     12\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     index_schema\u001b[38;5;241m=\u001b[39mmain_schema,\n\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: LocalFileStore.__init__() missing 1 required positional argument: 'root_path'"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore, LocalFileStore\n",
    "from langchain.storage._lc_store import create_kv_docstore\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "# store = InMemoryStore()\n",
    "fs = LocalFileStore(\"./store_location\")\n",
    "store = create_kv_docstore(fs)\n",
    "\n",
    "parent_doc_vector_store = LangChainRedis.from_documents(\n",
    "    documents=flattened_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    "    redis_url=REDIS_URL,\n",
    "    index_schema=main_schema,\n",
    ")\n",
    "\n",
    "parent_doc_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=parent_doc_vector_store,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "\n",
    "parent_doc_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=parent_doc_vector_store.as_retriever(\n",
    "        search_type=\"similarity_distance_threshold\",\n",
    "        search_kwargs={\"distance_threshold\":0.5}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RedisVectorStoreRetriever' object has no attribute 'similarity_search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[43mparent_doc_vector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimilarity_distance_threshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance_threshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat was Apple\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms revenue last year compared to this year??\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RedisVectorStoreRetriever' object has no attribute 'similarity_search'"
     ]
    }
   ],
   "source": [
    "parent_doc_vector_store.as_retriever(\n",
    "    search_type=\"similarity_distance_threshold\", \n",
    "    search_kwargs={\"distance_threshold\":0.5}\n",
    ").similarity_search(\"What was Apple's revenue last year compared to this year??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`index_schema` does not match generated metadata schema.\n",
      "If you meant to manually override the schema, please ignore this message.\n",
      "index_schema: {'vector': [{'name': 'text_embedding', 'algorithm': 'FLAT', 'dims': 384, 'distance_metric': 'COSINE', 'datatype': 'FLOAT32'}], 'text': [{'name': 'content'}], 'tag': [{'name': 'chunk_id'}, {'name': 'source_doc'}, {'name': 'doc_type'}, {'name': 'ticker'}, {'name': 'company_name'}, {'name': 'sector'}, {'name': 'asset_class'}, {'name': 'location'}, {'name': 'exchange'}, {'name': 'currency'}], 'numeric': [{'name': 'market_value'}, {'name': 'weight'}, {'name': 'notional_value'}, {'name': 'shares'}, {'name': 'price'}], 'content_vector_key': 'text_embedding'}\n",
      "generated_schema: {'text': [{'name': 'source'}], 'numeric': [], 'tag': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "\n",
    "# construct the vector store class from texts and metadata\n",
    "vector_store = LangChainRedis.from_documents(\n",
    "    documents=flattened_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    "    redis_url=REDIS_URL,\n",
    "    index_schema=main_schema,\n",
    ")\n",
    "\n",
    "parent_doc_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vector_store,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "parent_doc_retriever.add_documents(flattened_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"revenue and earnings in Apple's history. In fiscal year '18, our revenue grew by $36.4 billion. That's the equivalent of a Fortune 100 company in a single year. And we're capping all that off with our best September quarter ever. Revenue was $62.9 billion, ahead of our expectations. That's an increase of 20% over last year and our highest growth rate in 3 years. We also generated record Q4\", metadata={'id': 'chunk:2018-Nov-01-AAPL.txt-c7764e65-9866-4559-a1b7-8baa72e6b733', 'chunk_id': '2018-Nov-01-AAPL.txt-c7764e65-9866-4559-a1b7-8baa72e6b733', 'source_doc': '2018-Nov-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       " Document(page_content=\"revenue and earnings in Apple's history. In fiscal year '18, our revenue grew by $36.4 billion. That's the equivalent of a Fortune 100 company in a single year. And we're capping all that off with our best September quarter ever. Revenue was $62.9 billion, ahead of our expectations. That's an increase of 20% over last year and our highest growth rate in 3 years. We also generated record Q4\", metadata={'id': 'chunk:2018-Nov-01-AAPL.txt-b812d887-2f7f-496e-a23c-604b0a41216c', 'chunk_id': '2018-Nov-01-AAPL.txt-b812d887-2f7f-496e-a23c-604b0a41216c', 'source_doc': '2018-Nov-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       " Document(page_content='We repurchased 92.5 million Apple shares for $19.4 billion through open market transactions, and we paid $3.5 billion in dividends and equivalents. For our fiscal year 2018, revenue grew over $36 billion to $265.6 billion, an all-time record. Every geographic segment grew double digits with new records in the Americas, Europe, Japan and rest of Asia Pacific. We also set new all-time records for', metadata={'id': 'chunk:2018-Nov-01-AAPL.txt-7fd39f4a-037e-4a45-9263-49220a067eb5', 'chunk_id': '2018-Nov-01-AAPL.txt-7fd39f4a-037e-4a45-9263-49220a067eb5', 'source_doc': '2018-Nov-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       " Document(page_content='We repurchased 92.5 million Apple shares for $19.4 billion through open market transactions, and we paid $3.5 billion in dividends and equivalents. For our fiscal year 2018, revenue grew over $36 billion to $265.6 billion, an all-time record. Every geographic segment grew double digits with new records in the Americas, Europe, Japan and rest of Asia Pacific. We also set new all-time records for', metadata={'id': 'chunk:2018-Nov-01-AAPL.txt-d4786a03-c545-4936-8524-6b7c04237096', 'chunk_id': '2018-Nov-01-AAPL.txt-d4786a03-c545-4936-8524-6b7c04237096', 'source_doc': '2018-Nov-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"What was apples revenue last year?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ParentDocumentRetriever' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat was apples revenue last year?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mparent_doc_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m res\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ParentDocumentRetriever' object is not callable"
     ]
    }
   ],
   "source": [
    "query = \"What was apples revenue last year?\"\n",
    "res = parent_doc_retriever.invoke(query, distance_threshold=0.8)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "def get_search_kwargs(filters, distance_threshold):\n",
    "    return {\"distance_threshold\":distance_threshold,\"filter\":filters}\n",
    "\n",
    "parent_doc_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=parent_doc_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What was apples revenue last year?',\n",
       " 'result': \"I'm happy to help! However, I don't have any context provided about Apple's financial data. Could you please provide the relevant section from a 10K filing or another financial document that mentions Apple's revenue? That way, I can give an accurate answer.\\n\\nIf you could provide the necessary information, I'll be happy to help you with your question!\",\n",
       " 'source_documents': []}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question = \"What is the purpose of incorporating portions of the Registrant's definitive proxy statement into the Annual Report on Form 10-K?\"\n",
    "parent_doc_qa(\"What was apples revenue last year?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "testset_sample = pd.read_csv(\"basic_rag_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "parent_doc_dataset = create_evaluation_dataset(parent_doc_qa, testset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], [], [], [], [], [], []]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_doc_dataset['contexts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = evaluate(\n",
    "    eval_dataset,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_relevancy\n",
    "    ],\n",
    ")\n",
    "\n",
    "eval_df = eval_result.to_pandas()\n",
    "eval_df.to_csv(f\"{test_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redisvl-Q9FZQJWe-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
