{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating RAG\n",
    "\n",
    "The extent to which you can **evaluate** your system is the extent to which you can **improve** your system. Before going to prod, it is in your best interest to establish a framework for quickly and effectively understanding the quality of your RAG application. In this notebook, we will use the RAGAS framework, as proposed by [this paper](https://arxiv.org/pdf/2309.15217), to evaluate the RAG application developed in the previous examples. \n",
    "\n",
    "There is no substitute for reading the paper, but summarized below are the main metrics we will work with. Note: there are many more metrics that can be used depending on use case but these are the main ones covered in the paper so we will start there. \n",
    "\n",
    "# Quality metric breakdown\n",
    "\n",
    "The 3 quality metrics in the RAGAS framework are: **faithfulness**, **answer relevance**, and **context relevance**. Let's take a moment to define each and understand how we can arrive at their values.\n",
    "\n",
    "## Faithfulness\n",
    "\n",
    "An answer to a question can be said to be \"faithful\" if the **claims** that are made in the answer **can be inferred** from the **context**.\n",
    "\n",
    "The process for quantifying this score is as follows:\n",
    "\n",
    "1. Use the following prompt with an LLM to generate shorter more focused statements provided the question and answer.\n",
    "\n",
    "    > Given a question and answer, create one\n",
    "    > or more statements from each sentence\n",
    "    > in the given answer.\n",
    "    > question: [question]\n",
    "    > answer: [answer]\n",
    "\n",
    "2. For each generated statement, verify if it can be inferred from the context with the following prompt.\n",
    "\n",
    "    > Consider the given context and following\n",
    "    > statements, then determine whether they\n",
    "    > are supported by the information present\n",
    "    > in the context. Provide a brief explanation for each statement before arriving\n",
    "    > at the verdict (Yes/No). Provide a final\n",
    "    > verdict for each statement in order at the\n",
    "    > end in the given format. Do not deviate\n",
    "    > from the specified format.\n",
    "    > statement: [statement 1]\n",
    "    > ...\n",
    "    > statement: [statement n]\n",
    "\n",
    "3. The final score can then be calculated Faithfulness = (number of supported statements) / (total number of statements)\n",
    "\n",
    "## Answer Relevance\n",
    "\n",
    "An answer can be said to be relevant if it directly addresses the question (intuitively).\n",
    "\n",
    "The process for quantifying this score is:\n",
    "\n",
    "1. Use an LLM to generate \"hypothetical\" questions to a given answer with the following prompt:\n",
    "\n",
    "    > Generate a question for the given answer.\n",
    "    > answer: [answer]\n",
    "\n",
    "2. Embed the generated \"hypothetical\" questions as vectors.\n",
    "3. Calculate the cosine similarity of the hypothetical questions and the original question, sum those similarities, and divide by n.\n",
    "\n",
    "Expressed computationally: `Answer Relevance = sum(cos_sim((q, q_i) for q_i in n)) / n`\n",
    "\n",
    "## Context Relevance\n",
    "\n",
    "\"The context is considered relevant to the extent that it exclusively contains information that is needed to answer the question.\"\n",
    "\n",
    "The process:\n",
    "\n",
    "1. Use the following LLM prompt to extract a subset of sentences necessary to answer the question. The context is defined as the formatted search result from the vector database.\n",
    "\n",
    "    > Please extract relevant sentences from\n",
    "    > the provided context that can potentially\n",
    "    > help answer the following `{question}`. If no\n",
    "    > relevant sentences are found, or if you\n",
    "    > believe the question cannot be answered\n",
    "    > from the given context, return the phrase\n",
    "    > \"Insufficient Information\". While extracting candidate sentences you’re not allowed to make any changes to sentences\n",
    "    > from given `{context}`.\n",
    "\n",
    "2. Compute the context relevance score = (number of extracted sentences) / (total number of sentences in context)\n",
    "\n",
    "# Let's start coding!\n",
    "\n",
    "If you just finished the other examples this may already be done for you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Redis and create chunks to populate the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init Redis connection and index\n",
    "import os\n",
    "from redisvl.index import SearchIndex\n",
    "from redisvl.schema import IndexSchema\n",
    "from redis import Redis\n",
    "\n",
    "# init Redis connection\n",
    "# Replace values below with your own if using Redis Cloud instance\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\")\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")\n",
    "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")\n",
    "\n",
    "# If SSL is enabled on the endpoint, use redis:// as the URL prefix\n",
    "REDIS_URL = f\"redis://{REDIS_HOST}:{REDIS_PORT}\"\n",
    "os.environ[\"REDIS_URL\"] = REDIS_URL\n",
    "\n",
    "index_name = 'langchain'\n",
    "prefix = 'chunk'\n",
    "schema = IndexSchema.from_yaml('sec_index.yaml')\n",
    "client = Redis.from_url(REDIS_URL)\n",
    "\n",
    "# create an index from schema and the client\n",
    "index = SearchIndex(schema, client)\n",
    "index.create(overwrite=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure env\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dir_path = os.getcwd()\n",
    "parent_directory = os.path.dirname(dir_path)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"ROOT_DIR\"] = parent_directory\n",
    "\n",
    "#setting the local downloaded sentence transformer models f\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = f\"{parent_directory}/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Loaded doc info for  110 tickers...\n",
      "✅ Loaded 108 10K chunks for ticker=AAPL from AAPL-2021-10K.pdf\n",
      "✅ Loaded 94 10K chunks for ticker=AAPL from AAPL-2023-10K.pdf\n",
      "✅ Loaded 103 10K chunks for ticker=AAPL from AAPL-2022-10K.pdf\n",
      "✅ Loaded 27 earning_call chunks for ticker=AAPL from 2018-May-01-AAPL.txt\n",
      "✅ Loaded 31 earning_call chunks for ticker=AAPL from 2019-Oct-30-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2016-Jan-26-AAPL.txt\n",
      "✅ Loaded 31 earning_call chunks for ticker=AAPL from 2020-Jul-30-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2017-Aug-01-AAPL.txt\n",
      "✅ Loaded 29 earning_call chunks for ticker=AAPL from 2020-Jan-28-AAPL.txt\n",
      "✅ Loaded 34 earning_call chunks for ticker=AAPL from 2016-Apr-26-AAPL.txt\n",
      "✅ Loaded 29 earning_call chunks for ticker=AAPL from 2017-Jan-31-AAPL.txt\n",
      "✅ Loaded 28 earning_call chunks for ticker=AAPL from 2019-Apr-30-AAPL.txt\n",
      "✅ Loaded 26 earning_call chunks for ticker=AAPL from 2017-Nov-02-AAPL.txt\n",
      "✅ Loaded 31 earning_call chunks for ticker=AAPL from 2016-Oct-25-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2016-Jul-26-AAPL.txt\n",
      "✅ Loaded 27 earning_call chunks for ticker=AAPL from 2017-May-02-AAPL.txt\n",
      "✅ Loaded 32 earning_call chunks for ticker=AAPL from 2019-Jul-30-AAPL.txt\n",
      "✅ Loaded 31 earning_call chunks for ticker=AAPL from 2019-Jan-29-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2018-Jul-31-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2018-Feb-01-AAPL.txt\n",
      "✅ Loaded 33 earning_call chunks for ticker=AAPL from 2018-Nov-01-AAPL.txt\n",
      "✅ Loaded 30 earning_call chunks for ticker=AAPL from 2020-Apr-30-AAPL.txt\n",
      "✅✅✅Loaded a total of 874 chunks from 3 10Ks and 19 earning calls for 1 tickers.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings \n",
    "from ingestion import get_sec_data\n",
    "from ingestion import redis_bulk_upload\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", cache_folder=os.getenv(\"TRANSFORMERS_CACHE\", f\"{parent_directory}/models\"))\n",
    "sec_data = get_sec_data()\n",
    "\n",
    "chunks = redis_bulk_upload(sec_data, index, embeddings, tickers=['AAPL'], chunk_size=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_chunks = [item for sublist in chunks for item in sublist]\n",
    "len(flattened_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate index and create vector store\n",
    "This is entirely the same as we have done in the previous examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Redis as LangChainRedis\n",
    "from utils import create_langchain_schemas_from_redis_schema\n",
    "\n",
    "index_name = 'langchain'\n",
    "\n",
    "vec_schema , main_schema = create_langchain_schemas_from_redis_schema('sec_index.yaml')\n",
    "\n",
    "rds = LangChainRedis.from_existing_index(\n",
    "    embedding=embeddings, \n",
    "    index_name= index_name, \n",
    "    schema = main_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out!\n",
    "We can see the vector store is populated and returning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Earlier this month, released macOS Catalina with all new entertainment apps, innovative Sidecar feature that uses iPad to expand Mac workspace and new accessibility tools that enable users to control their Mac entirely with their voice. 1. Catalina brings Apple Arcade experience to Mac. 1. Already seeing some third-party developers bring their iPad apps to Mac App Store with Mac Catalyst, including Twitter, Post-it and more. 4. Launching newly redesigned Mac Pro this fall, which Co. is manufacturing in Austin, Texas. 7. Others: 1. In FY19, crossed $100b in revenue in US for first time. 2. Introduce new services from Apple Card to Apple TV+ and generated over $46b in total Services revenue, setting new yearly Services records in all five geographic segments and driving Services business to size of Fortune 70 co. 3. Delivered new hardware in all device categories. 4. Wearables business showed explosive growth and generated more annual revenue than two-thirds of companies in Fortune 500. 5. Set yearly revenue record for Mac. 6. Outside of iPhone, revenue grew by $17b to almost $118b. 7. Overall success was achieved widely across markets with annual revenue records in US, Canada, Brazil, UK, Germany, France, Italy, Poland, Korea, Malaysia, Philippines and Vietnam. 8. Believes that Co. leads in innovation because AAPL leads with its values. 9.\\n\\nAt time of urgency and action on climate change, continues to drive breakthroughs in clean power, sustainable materials and device recycling. 1. By running 100% of global operations on renewable energy and challenging entire network of suppliers do the same, Co. is driving virtuous cycle of demand for clean sources of power. 2. Sees award Co. recently received from United Nation's Global Climate Action program as mandate to deepen this vital work. 10. Continues to invent and improves on cutting-edge renewable materials, including 100% recycled aluminum alloy found in many of Co.'s products. 1. Added rare earth elements to list of recycled materials with introduction of iPhone 11. 2. Disassembling, recycling or refurbishing millions of devices every year with help of Daisy, recycling robot, and pushing entire global supply chain toward recycled or renewable materials. 11. Driving access to critical coding skills development to educators and students through programs like teaching coding academies and free Everyone Can Code curriculum. 12. Continues to put user privacy at center of everything that Co. does.\", metadata={'id': 'chunk:2019-Oct-30-AAPL.txt-727fe74e-34ab-4cd0-beb4-7bac734ccd0c', 'chunk_id': '2019-Oct-30-AAPL.txt-727fe74e-34ab-4cd0-beb4-7bac734ccd0c', 'source_doc': '2019-Oct-30-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rds.similarity_search(\"What was apples revenue last year?\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# we will use llama3 as our local llm for this use case\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt():\n",
    "    \"\"\"Create the QA chain.\"\"\"\n",
    "    from langchain.prompts import PromptTemplate\n",
    "\n",
    "    # Define our prompt\n",
    "    prompt_template = \"\"\"Use the following pieces of context from financial 10k filings data to answer the user question at the end. Only use the result from tools and evidence provided to you. If you don't know the answer, say that you don't know, don't try to make up an answer. Provide the source of the document that you used to get the answer.\n",
    "\n",
    "    This should be in the following format:\n",
    "\n",
    "    Question: [question here]\n",
    "    Answer: [answer here]\n",
    "    Source: [source document here]\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Context:\n",
    "    ---------\n",
    "    {context}\n",
    "    ---------\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def get_search_kwargs(filters, distance_threshold):\n",
    "    return {\"distance_threshold\":distance_threshold,\"filter\":filters}\n",
    "    \n",
    "\n",
    "# options \n",
    "# search_type=\"similarity_distance_threshold\",\n",
    "# search_kwargs={\"distance_threshold\":0.8, 'include_metadata': True}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=rds.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have our RAG QA to test out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': \"What was Apple's revenue last year compared to this year??\",\n",
       " 'result': \"Question: What was Apple's revenue last year compared to this year??\\nAnswer: According to the context, in fiscal year '18, Apple's revenue grew by $36.4 billion, and for Q4, revenue was $62.9 billion, an increase of 20% over last year.\\nSource: The source document used is a financial 10K filing data, specifically from Apple's quarterly and annual reports filed with the Securities and Exchange Commission (SEC).\",\n",
       " 'source_documents': [Document(page_content=\"Thank you, Nancy. Good afternoon, everyone, and thanks for joining us. I just got back from Brooklyn, where we marked our fourth major launch at the end of the year. In addition to being a great time, it put an exclamation point at the end of a remarkable fiscal 2018. This year, we shipped our 2 billionth iOS device, celebrated the 10th anniversary of the App Store and achieved the strongest revenue and earnings in Apple's history. In fiscal year '18, our revenue grew by $36.4 billion. That's the equivalent of a Fortune 100 company in a single year. And we're capping all that off with our best September quarter ever. Revenue was $62.9 billion, ahead of our expectations. That's an increase of 20% over last year and our highest growth rate in 3 years. We also generated record Q4 earnings with 41% year-over-year growth in EPS. Record results from iPhone, Services and Wearables drove our momentum, and we produced strong double-digit revenue growth in all of our geographic segments. It was a big year and a big quarter for iPhone. Q4 revenue was up 29% over last year, an increase of over $8 billion to a new September quarter record, fueled by continued momentum for iPhone 8, 8 Plus and X and the very successful launch of iPhone Xs and iPhone Xs Max. These latest devices are our most advanced iPhones ever with the industry's first 7-nanometer A12 Bionic chip with an Apple-designed 8-core Neural Engine capable of executing an astounding 5 trillion operations per second.\", metadata={'id': 'chunk:2018-Nov-01-AAPL.txt-efdd2927-b5dd-4cf8-9686-3529c73bfe6c', 'chunk_id': '2018-Nov-01-AAPL.txt-efdd2927-b5dd-4cf8-9686-3529c73bfe6c', 'source_doc': '2018-Nov-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content=\"According to App Annie's latest report, App Store continues to build preferred destination for customer purchases by wide margin, generating nearly twice revenue of Google Play. 3. Across all Services offerings, paid subscriptions reached 240m, with growth of 58% over last year. 1. Major contributor to overall strong growth in revenue. 4. Apple Watch: 1. Best qtr. ever. 2. Adding results from Beats and AirPods, total revenue from wearables up almost 70% YoverY. 3. Wearables second largest contributor to revenue growth after iPhone. 1. Started only three years ago. 4. In total, other products category set new all-time record with quarterly revenue exceeding $5b for first time. 5. Mac: 1. Sold 5.1m Macs. 1. Translates to 2% YoverY increase in avg. sales per week. 2. Performance particularly strong in emerging markets with unit sales up 13% YoverY and with all-time records in Latin America, India, Turkey and Central and Eastern Europe. 3. Worldwide, active installed base of Macs up double digits YoverY to new record. 6. iPad: 1. Growth qtr. 2. Sold 13.2m units. 1. Avg. iPad sales per week [up 8%] over last year's Dec. qtr. 3. Sales grew strong double digits in many emerging markets including Latin America, Middle East, Central and Eastern Europe and India, and developed markets including Japan, Australia and Korea. 4. Active installed base of iPad has grown every qtr. since launch in 2010. 1.\", metadata={'id': 'chunk:2018-Feb-01-AAPL.txt-c4d847fd-2ddc-4e5e-aa16-a7022ded1402', 'chunk_id': '2018-Feb-01-AAPL.txt-c4d847fd-2ddc-4e5e-aa16-a7022ded1402', 'source_doc': '2018-Feb-01-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content=\"Earlier this month, released macOS Catalina with all new entertainment apps, innovative Sidecar feature that uses iPad to expand Mac workspace and new accessibility tools that enable users to control their Mac entirely with their voice. 1. Catalina brings Apple Arcade experience to Mac. 1. Already seeing some third-party developers bring their iPad apps to Mac App Store with Mac Catalyst, including Twitter, Post-it and more. 4. Launching newly redesigned Mac Pro this fall, which Co. is manufacturing in Austin, Texas. 7. Others: 1. In FY19, crossed $100b in revenue in US for first time. 2. Introduce new services from Apple Card to Apple TV+ and generated over $46b in total Services revenue, setting new yearly Services records in all five geographic segments and driving Services business to size of Fortune 70 co. 3. Delivered new hardware in all device categories. 4. Wearables business showed explosive growth and generated more annual revenue than two-thirds of companies in Fortune 500. 5. Set yearly revenue record for Mac. 6. Outside of iPhone, revenue grew by $17b to almost $118b. 7. Overall success was achieved widely across markets with annual revenue records in US, Canada, Brazil, UK, Germany, France, Italy, Poland, Korea, Malaysia, Philippines and Vietnam. 8. Believes that Co. leads in innovation because AAPL leads with its values. 9.\\n\\nAt time of urgency and action on climate change, continues to drive breakthroughs in clean power, sustainable materials and device recycling. 1. By running 100% of global operations on renewable energy and challenging entire network of suppliers do the same, Co. is driving virtuous cycle of demand for clean sources of power. 2. Sees award Co. recently received from United Nation's Global Climate Action program as mandate to deepen this vital work. 10. Continues to invent and improves on cutting-edge renewable materials, including 100% recycled aluminum alloy found in many of Co.'s products. 1. Added rare earth elements to list of recycled materials with introduction of iPhone 11. 2. Disassembling, recycling or refurbishing millions of devices every year with help of Daisy, recycling robot, and pushing entire global supply chain toward recycled or renewable materials. 11. Driving access to critical coding skills development to educators and students through programs like teaching coding academies and free Everyone Can Code curriculum. 12. Continues to put user privacy at center of everything that Co. does.\", metadata={'id': 'chunk:2019-Oct-30-AAPL.txt-727fe74e-34ab-4cd0-beb4-7bac734ccd0c', 'chunk_id': '2019-Oct-30-AAPL.txt-727fe74e-34ab-4cd0-beb4-7bac734ccd0c', 'source_doc': '2019-Oct-30-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       "  Document(page_content='Revenue almost $6.1b, including $548m received from patent infringement dispute. 1. Excluding that amount, revenue was $5.5b. 1. New all-time record and increase of 15% over last year due in large part to strong growth from apps. 2. Revenue from App Store increased 27%. 1. Number of transacting customers grew 18%; all-time record. 3. Among customers who purchase apps and content from iTunes Stores, avg. amount spent for customer reached an all-time high in Dec. qtr. 8. Other Details: 1. Revenue from other products grew strongly. 1. Up 62% YoverY due to: 1. Growing contribution from Apple Watch. 2. Successful launch of new Apple TV. 2. Both aforementioned established new all-time quarterly records. 2. Expanded Apple Watch distribution significantly over course of qtr. 1. Experienced especially strong results during holiday buying season. 9. Cash Position: 1. 1Q16-end [$215.7b] in cash plus marketable securities. 1. Increased $10.1b sequentially. 2. $200b of this cash or 93% of total was outside US. 2. Returned over $9b to investors. 3. Paid $3b in dividends and equivalents. 4. Spent $3b to repurchase 26m AAPL shares through open market transactions. 5. Launched sixth share repurchase program, spending $3b and receiving an initial delivery of [20.4m shares]. 6. Now completed over $153b of our $200b program, including $110b in share purchases. 7. Plans to provide update on capital return program during 2Q results in April. 1.\\n\\nPlans to be active in US and international debt markets in 2016 in order to fund capital return activities. 2. On 01/26/16, Board of Directors declared cash dividend of $0.52 per share of common stock payable on 02/11/16 to shareholders of record as of 02/08/16. 10. 2Q16 Guidance: 1. Revenue $50-53b. 1. Providing wider range for revenue than usual for 2Q because of volatility seeing in economy and financial and currency markets. 2. GM 39.0-39.5%. 1. Believes these are extremely strong margins in light of headwinds faced from FX and sequential loss of leverage. 3. OpEx $6.0-6.1b. 4. OI&E about $325m. 5. Tax rate about 25.5%. 6. Does not provide guidance beyond current qtr. 1. Difficult to forecast economic and FX factors. 2. At this point, believes March qtr. faces most difficult YoverY compare relative to rest of year.', metadata={'id': 'chunk:2016-Jan-26-AAPL.txt-adea6e3d-91c8-4eff-b77c-1b240ad2dea7', 'chunk_id': '2016-Jan-26-AAPL.txt-adea6e3d-91c8-4eff-b77c-1b240ad2dea7', 'source_doc': '2016-Jan-26-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'})]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What was Apple's revenue last year compared to this year??\"\n",
    "res=qa(query)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup complete!\n",
    "Now let's generate some test questions to evaluate the answering abilities of the RAG QA using the metrics we introduced at the beginning. To do this we can use the LLM to come up with some potential questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What is Apple's total revenue for 2023 compared to the previous year?\",\n",
       " 'What percentage increase in Services revenue did Apple report in 2023?',\n",
       " \"How much has Apple's gross margin increased/decreased over the past three years?\",\n",
       " \"What was Apple's operating cash flow for 2023, and how does it compare to 2022?\",\n",
       " 'In what sectors did Apple see significant growth in its hardware sales (e.g., Mac, iPad, etc.)?',\n",
       " \"By what percentage did Apple's iPhone revenue increase or decrease in 2023 compared to the previous year?\",\n",
       " \"What was Apple's research and development expense for 2023, and how does it compare to 2022?\",\n",
       " \"How has Apple's capital expenditures changed over the past five years?\",\n",
       " 'In what regions did Apple see significant growth in its sales (e.g., Asia, Americas, etc.)?',\n",
       " \"By what percentage did Apple's China revenue increase or decrease in 2023 compared to the previous year?\",\n",
       " \"What was Apple's effective tax rate for 2023, and how does it compare to the previous year?\",\n",
       " \"How much has Apple's net income increased/decreased over the past five years?\",\n",
       " \"What is Apple's total debt as of 2023, and how does it compare to 2022?\",\n",
       " 'In what areas did Apple see significant growth in its wearables sales (e.g., Apple Watch, AirPods, etc.)?',\n",
       " \"How much was Apple's dividend per share for 2023, and how does it compare to the previous year?\"]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"evaluation/questions.json\", \"r\") as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(questions):\n",
    "    prompt = \"\"\"\n",
    "        You are a helpful question generating bot.\n",
    "        Generate 15 questions you might ask about Apple's financial performance from it's 2023 annual report, earnings calls,\n",
    "        and other financial documents. Return the response without any additional text as a json object of the form\n",
    "        {\"questions\": [question1, question2, ..., question15]}\n",
    "    \"\"\"\n",
    "\n",
    "    questions = json.loads(llm.generate([prompt]).generations[0][0].text)[\"questions\"]\n",
    "    questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for creating test dataset\n",
    "\n",
    "In the following code we take a list of questions and a QA retrieval chain as input. We call the chain and store the answer returned along with the context (aka source documents) to be used as the essential data for our evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define reusable helper function for evaluating our test set against different chains\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_relevancy,\n",
    ")\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "def parse_contexts(source_docs):\n",
    "    return [doc.page_content for doc in source_docs]\n",
    "\n",
    "def create_evaluation_dataset(chain, questions):\n",
    "    res_set = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": [],\n",
    "    }\n",
    "\n",
    "    for question in questions:\n",
    "        # call QA chain\n",
    "        result = chain(question)\n",
    "\n",
    "        res_set[\"question\"].append(question)\n",
    "        res_set[\"answer\"].append(result[\"result\"])\n",
    "        res_set[\"contexts\"].append(parse_contexts(result[\"source_documents\"]))\n",
    "    return Dataset.from_dict(res_set)\n",
    "\n",
    "def evaluate_chain(chain, questions, test_name):\n",
    "    eval_dataset = create_evaluation_dataset(chain, questions)\n",
    "\n",
    "    eval_result = evaluate(\n",
    "        eval_dataset,\n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_relevancy\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    eval_df = eval_result.to_pandas()\n",
    "    # store the results of our test for future reference in csv\n",
    "    eval_df.to_csv(f\"{test_name}.csv\")\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# by default ragas evaluation uses OpenAI\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OPENAI_API_KEY\")\n",
    "\n",
    "basic_rag_test = evaluate_chain(qa, questions, \"basic_rag_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.556230</td>\n",
       "      <td>0.585421</td>\n",
       "      <td>0.008943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.262812</td>\n",
       "      <td>0.495011</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.951487</td>\n",
       "      <td>0.006849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.976251</td>\n",
       "      <td>0.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy  context_relevancy\n",
       "count     15.000000         15.000000          15.000000\n",
       "mean       0.556230          0.585421           0.008943\n",
       "std        0.262812          0.495011           0.004356\n",
       "min        0.000000          0.000000           0.004274\n",
       "25%        0.416667          0.000000           0.005445\n",
       "50%        0.600000          0.951487           0.006849\n",
       "75%        0.732143          0.976251           0.011905\n",
       "max        1.000000          1.000000           0.016667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_rag_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "We can see from the above results that our basic RAG didn't score particularly well. This is okay because now that we have a baseline for the performance of our RAG, we can begin to try different techniques to improve our results. The reason it is so important to have a framework in place for evaluation is now we can properly experiment with different techniques to see what improves our particular system.\n",
    "\n",
    "One technique we could try is to implement a parent document retriever. A parent document retriever attempts to optimize two competing objectives within RAG - 1) smaller chunks can lead to better embeddings since there is less context to lose the point (so to speak) 2) larger chunks help retain what could be valuable overall context to retrieval. Parent document retrieval allows for the initial query search on smaller chunks for specificity but returns the larger chunks for more complete context. \n",
    "\n",
    "Let's perform an experiment to see if this technique improves our metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.document_loaders import TextLoader, UnstructuredFileLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.redis import Redis as LangChainRedis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "CHAT_MODEL = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will make a new index for this example defined directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader, TextLoader\n",
    "\n",
    "\n",
    "# load our multi modal docs\n",
    "source_docs = []\n",
    "\n",
    "for doc in sec_data[\"AAPL\"][\"10K_files\"]:\n",
    "    loader = UnstructuredFileLoader(\n",
    "        doc, mode=\"single\", strategy=\"fast\"\n",
    "    )\n",
    "\n",
    "    source_docs.extend(loader.load())\n",
    "\n",
    "for doc in sec_data[\"AAPL\"][\"transcript_files\"]:\n",
    "    loader = TextLoader(doc)\n",
    "\n",
    "    source_docs.extend(loader.load())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "PARENT_CHUNK_SIZE = 5000\n",
    "CHILD_CHUNK_SIZE = 400\n",
    "\n",
    "# This text splitter is used to create the parent documents aka larger chunks\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=PARENT_CHUNK_SIZE)\n",
    "\n",
    "# This text splitter is used to create the child documents\n",
    "# It should create documents smaller than the parent\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=CHILD_CHUNK_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it is **critical** that our index includes the `doc_id` field otherwise the parent document linking will not happen correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "# with langchain we can manually modify the default vector schema configuration\n",
    "vector_schema = {\n",
    "    \"name\": \"chunk_vector\",        # name of the vector field in langchain\n",
    "    \"algorithm\": \"HNSW\",           # could use HNSW instead\n",
    "    \"dims\": 384,                   # set based on the HF model embedding dimension\n",
    "    \"distance_metric\": \"COSINE\",   # could use EUCLIDEAN or IP\n",
    "    \"datatype\": \"FLOAT32\",\n",
    "}\n",
    "\n",
    "# here we can define the entire schema spec for our index in LangChain\n",
    "index_schema = {\n",
    "    \"vector\": [vector_schema],\n",
    "    \"text\": [{\"name\": \"content\"}, {\"name\": \"doc_id\"}],\n",
    "    \"content_vector_key\": \"chunk_vector\" ,   # name of the vector field in langchain\n",
    "}\n",
    "\n",
    "vector_store = LangChainRedis(\n",
    "    REDIS_URL,\n",
    "    \"child_docs\",\n",
    "    embeddings,\n",
    "    index_schema=index_schema\n",
    ")\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vector_store,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we are adding the source documents and the ParentDocumentRetriever will automatically split them into parent and child documents\n",
    "retriever.add_documents(source_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='The Company evaluates the performance of its reportable segments based on net sales and operating income. Net sales for geographic segments are generally based on the location of customers and sales through the Company’s retail stores located in those geographic locations. Operating income for each segment includes net sales to third parties, related cost of sales and operating expenses directly attributable to the segment. Advertising expenses are generally included in the geographic segment in which the expenditures are incurred. Operating income for each segment excludes other income and expense and certain expenses managed outside the reportable segments. Costs excluded from segment operating income include various corporate expenses such as research and development (“R&D”), corporate marketing expenses, certain share-based compensation expenses, income taxes, various nonrecurring charges and other separately managed general and administrative costs. The Company does not include intercompany transfers between segments for management reporting purposes.\\n\\nNote 2 – Revenue\\n\\nNet sales disaggregated by significant products and services for 2022, 2021 and 2020 were as follows (in millions):\\n\\n2022\\n\\n2021\\n\\n(1)\\n\\niPhone (1) Mac iPad Wearables, Home and Accessories Services\\n\\n(1)\\n\\n(3)\\n\\nTotal net sales\\n\\n(4)\\n\\n(1)(2)\\n\\n$\\n\\n$\\n\\n205,489 $ 40,177 29,292 41,241 78,129 394,328 $\\n\\n191,973 $ 35,190 31,862 38,367 68,425 365,817 $\\n\\n(1) Products net sales include amortization of the deferred value of unspecified software upgrade rights, which are bundled in the\\n\\nsales price of the respective product.\\n\\n(2) Wearables, Home and Accessories net sales include sales of AirPods, Apple TV, Apple Watch, Beats products, HomePod mini\\n\\nand accessories.\\n\\n(3) Services net sales include sales from the Company’s advertising, AppleCare, cloud, digital content, payment and other services. Services net sales also include amortization of the deferred value of services bundled in the sales price of certain products.\\n\\n(4)\\n\\nIncludes $7.5 billion of revenue recognized in 2022 that was included in deferred revenue as of September 25, 2021, $6.7 billion of revenue recognized in 2021 that was included in deferred revenue as of September 26, 2020, and $5.0 billion of revenue recognized in 2020 that was included in deferred revenue as of September 28, 2019.\\n\\nThe Company’s proportion of net sales by disaggregated revenue source was generally consistent for each reportable segment in Note 11, “Segment Information and Geographic Data” for 2022, 2021 and 2020, except in Greater China, where iPhone revenue represented a moderately higher proportion of net sales in 2022 and 2021.\\n\\nAs of September 24, 2022 and September 25, 2021, the Company had total deferred revenue of $12.4 billion and $11.9 billion, respectively. As of September 24, 2022, the Company expects 64% of total deferred revenue to be realized in less than a year, 27% within one-to-two years, 7% within two-to-three years and 2% in greater than three years.\\n\\nApple Inc. | 2022 Form 10-K | 37\\n\\n2020\\n\\n137,781 28,622 23,724 30,620 53,768 274,515\\n\\nNote 3 – Financial Instruments\\n\\nCash, Cash Equivalents and Marketable Securities\\n\\nThe following tables show the Company’s cash, cash equivalents and marketable securities by significant investment category as of September 24, 2022 and September 25, 2021 (in millions):\\n\\n2022\\n\\nAdjusted Cost\\n\\nUnrealized Gains\\n\\nUnrealized Losses\\n\\nFair Value\\n\\nCash and Cash Equivalents\\n\\nCurrent Marketable Securities\\n\\nCash\\n\\n$\\n\\n18,546 $\\n\\n— $\\n\\n— $\\n\\n18,546 $\\n\\n18,546 $\\n\\n— $\\n\\nLevel 1\\n\\n(1) :\\n\\nMoney market funds Mutual funds Subtotal (2) :\\n\\nLevel 2\\n\\n2,929 274\\n\\n3,203\\n\\n— —\\n\\n—\\n\\n— (47)\\n\\n(47)\\n\\n2,929 227\\n\\n3,156\\n\\n2,929 —\\n\\n2,929\\n\\n— 227\\n\\n227\\n\\nU.S. Treasury securities U.S. agency securities Non-U.S. government securities Certificates of deposit and time\\n\\n25,134 5,823 16,948\\n\\n— — 2\\n\\n(1,725) (655) (1,201)\\n\\n23,409 5,168 15,749\\n\\n338 — —\\n\\n5,091 240 8,806\\n\\ndeposits\\n\\nCommercial paper Corporate debt securities Municipal securities Mortgage- and asset-backed\\n\\n2,067 718 87,148 921\\n\\n— — 9 —\\n\\n— — (7,707) (35)\\n\\n2,067 718 79,450 886\\n\\n1,805 28 — —\\n\\n262 690 9,023 266\\n\\nsecurities Subtotal\\n\\n22,553\\n\\n161,312\\n\\n—\\n\\n11\\n\\n(2,593)\\n\\n(13,916)\\n\\n19,960\\n\\n147,407\\n\\n—\\n\\n2,171\\n\\n53\\n\\n24,431\\n\\nTotal\\n\\n(3)\\n\\n$ 183,061 $\\n\\n11 $\\n\\n(13,963) $ 169,109 $\\n\\n23,646 $\\n\\n24,658 $\\n\\n2021\\n\\nCash\\n\\n$\\n\\nAdjusted Cost 17,305 $\\n\\nUnrealized Gains\\n\\n— $\\n\\nUnrealized Losses\\n\\n— $\\n\\nFair Value\\n\\n17,305 $\\n\\nCash and Cash Equivalents\\n\\n17,305 $\\n\\nCurrent Marketable Securities\\n\\n— $\\n\\nLevel 1\\n\\n(1) :\\n\\nMoney market funds Mutual funds Subtotal (2) : Equity securities U.S. Treasury securities U.S. agency securities Non-U.S. government securities Certificates of deposit and time\\n\\nLevel 2\\n\\n9,608 175\\n\\n9,783\\n\\n1,527 22,878 8,949 20,201\\n\\n— 11\\n\\n11\\n\\n— 102 2 211\\n\\n— (1)\\n\\n(1)\\n\\n(564) (77) (64) (101)\\n\\n9,608 185\\n\\n9,793\\n\\n963 22,903 8,887 20,311\\n\\n9,608 —\\n\\n9,608\\n\\n— 3,596 1,775 390\\n\\n— 185\\n\\n185\\n\\n963 6,625 1,930 3,091\\n\\ndeposits', metadata={'source': '/Users/robert.shelton/Documents/boa/financial-vss/resources/filings/AAPL/AAPL-2022-10K.pdf'})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test that the retirever works\n",
    "retrieved_docs = retriever.invoke(\"apples's revenue 2023\")\n",
    "retrieved_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the same but use our new retriever\n",
    "parent_doc_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"What is Apple's total revenue for 2023 compared to the previous year?\",\n",
    " 'What percentage increase in Services revenue did Apple report in 2023?',\n",
    " \"How much has Apple's gross margin increased/decreased over the past three years?\",\n",
    " \"What was Apple's operating cash flow for 2023, and how does it compare to 2022?\",\n",
    " 'In what sectors did Apple see significant growth in its hardware sales (e.g., Mac, iPad, etc.)?',\n",
    " \"By what percentage did Apple's iPhone revenue increase or decrease in 2023 compared to the previous year?\",\n",
    " \"What was Apple's research and development expense for 2023, and how does it compare to 2022?\",\n",
    " \"How has Apple's capital expenditures changed over the past five years?\",\n",
    " 'In what regions did Apple see significant growth in its sales (e.g., Asia, Americas, etc.)?',\n",
    " \"By what percentage did Apple's China revenue increase or decrease in 2023 compared to the previous year?\",\n",
    " \"What was Apple's effective tax rate for 2023, and how does it compare to the previous year?\",\n",
    " \"How much has Apple's net income increased/decreased over the past five years?\",\n",
    " \"What is Apple's total debt as of 2023, and how does it compare to 2022?\",\n",
    " 'In what areas did Apple see significant growth in its wearables sales (e.g., Apple Watch, AirPods, etc.)?',\n",
    " \"How much was Apple's dividend per share for 2023, and how does it compare to the previous year?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef27d1877d7e4cea82cf208e6b3a4b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_doc_test = evaluate_chain(parent_doc_qa, questions, \"parent_doc_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.568745</td>\n",
       "      <td>0.434157</td>\n",
       "      <td>0.009992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.323349</td>\n",
       "      <td>0.481311</td>\n",
       "      <td>0.010279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.923713</td>\n",
       "      <td>0.008069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981103</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy  context_relevancy\n",
       "count     15.000000         15.000000          15.000000\n",
       "mean       0.568745          0.434157           0.009992\n",
       "std        0.323349          0.481311           0.010279\n",
       "min        0.000000          0.000000           0.002907\n",
       "25%        0.333333          0.000000           0.004517\n",
       "50%        0.500000          0.000000           0.006135\n",
       "75%        0.916667          0.923713           0.008069\n",
       "max        1.000000          0.981103           0.040541"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_doc_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb856d671cb47afa5e6359e5b200a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_data_5000 = evaluate_chain(parent_doc_qa, questions, \"parent_5000_doc_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.596935</td>\n",
       "      <td>0.528126</td>\n",
       "      <td>0.004088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.323664</td>\n",
       "      <td>0.448377</td>\n",
       "      <td>0.001441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.820075</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.893182</td>\n",
       "      <td>0.005116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy  context_relevancy\n",
       "count     15.000000         15.000000          15.000000\n",
       "mean       0.596935          0.528126           0.004088\n",
       "std        0.323664          0.448377           0.001441\n",
       "min        0.000000          0.000000           0.002174\n",
       "25%        0.358974          0.000000           0.002829\n",
       "50%        0.571429          0.820075           0.004132\n",
       "75%        0.898990          0.893182           0.005116\n",
       "max        1.000000          0.952074           0.006494"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_5000.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import BaseRagasLLM\n",
    "\n",
    "\n",
    "class OllamaWrapper(BaseRagasLLM):\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def generate_text(self, prompt):\n",
    "        return self.llm.generate(prompt)\n",
    "    \n",
    "    async def agenerate_text(self, prompt):\n",
    "        return self.llm.generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OllamaWrapper(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm afraid I have some bad news...\\n\\nAs of March 2023, the latest publicly available financial information for Apple is from its fiscal year 2022 (October 30, 2021 to September 24, 2022). The company reported:\\n\\n* Revenue: $394 billion\\n* Net income: $94.7 billion\\n\\nPlease note that these figures are subject to change and may not reflect the company's current financial performance.\\n\\nFor future revenue figures, I recommend checking Apple's investor relations webpage or seeking out more recent reports from reputable financial sources.\\n\\nWould you like me to help with anything else?\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = llm(\"what was apple's revenue in 2023?\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b22eb33a0ae4daabe4f09ce525d1cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_data_5000_parent_doc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_relevancy\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mollama\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# eval_df = eval_result.to_pandas()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# # store the results of our test for future reference in csv\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# eval_df.to_csv(\"parent_5000_doc_test.csv\")\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/evaluation.py:230\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[1;32m    227\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;241m==\u001b[39m []:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/executor.py:132\u001b[0m, in \u001b[0;36mExecutor.results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m executor_job\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[43mexecutor_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-460:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/executor.py\", line 96, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/executor.py\", line 84, in _aresults\n",
      "    raise e\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/executor.py\", line 79, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/asyncio/tasks.py\", line 615, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/executor.py\", line 38, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/executor.py\", line 112, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/metrics/base.py\", line 123, in ascore\n",
      "    raise e\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/metrics/base.py\", line 119, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/metrics/_faithfulness.py\", line 248, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/ragas/llms/base.py\", line 92, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tenacity/__init__.py\", line 410, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tenacity/__init__.py\", line 183, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: OllamaWrapper.agenerate_text() got an unexpected keyword argument 'n'\n"
     ]
    }
   ],
   "source": [
    "eval_result = evaluate(\n",
    "    eval_data_5000_parent_doc,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_relevancy\n",
    "    ],\n",
    "    llm=ollama\n",
    ")\n",
    "\n",
    "# eval_df = eval_result.to_pandas()\n",
    "# # store the results of our test for future reference in csv\n",
    "# eval_df.to_csv(\"parent_5000_doc_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Apple's total revenue for 2023 compare...</td>\n",
       "      <td>According to the provided context from financi...</td>\n",
       "      <td>[The Company evaluates the performance of its ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What percentage increase in Services revenue d...</td>\n",
       "      <td>According to the text:\\n\\n\"Services net sales ...</td>\n",
       "      <td>[(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much has Apple's gross margin increased/de...</td>\n",
       "      <td>Based on the provided financial data, we can c...</td>\n",
       "      <td>[Japan\\n\\nJapan net sales decreased during 202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was Apple's operating cash flow for 2023,...</td>\n",
       "      <td>I'm happy to help! However, I need to point ou...</td>\n",
       "      <td>[Beginning balances\\n\\nCommon stock issued Com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In what sectors did Apple see significant grow...</td>\n",
       "      <td>Based on the context from the financial 10K fi...</td>\n",
       "      <td>[1. Highlights:\\n          1. Revenue $58b.\\n ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By what percentage did Apple's iPhone revenue ...</td>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>[1. Highlights:\\n          1. In uncertain env...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was Apple's research and development expe...</td>\n",
       "      <td>I'm happy to help! However, I need to clarify ...</td>\n",
       "      <td>[(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How has Apple's capital expenditures changed o...</td>\n",
       "      <td>The context provided does not mention anything...</td>\n",
       "      <td>[Japan\\n\\nJapan net sales decreased during 202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In what regions did Apple see significant grow...</td>\n",
       "      <td>According to the context, Apple saw significan...</td>\n",
       "      <td>[1. Highlights:\\n          1. Best June qtr. r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>By what percentage did Apple's China revenue i...</td>\n",
       "      <td>The answer is not explicitly mentioned in the ...</td>\n",
       "      <td>[1. Highlights:\\n          1. Dec. qtr. revenu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What was Apple's effective tax rate for 2023, ...</td>\n",
       "      <td>Based on the provided context, there is no men...</td>\n",
       "      <td>[(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How much has Apple's net income increased/decr...</td>\n",
       "      <td>Based on the provided financial data, we can c...</td>\n",
       "      <td>[See accompanying Notes to Consolidated Financ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is Apple's total debt as of 2023, and how...</td>\n",
       "      <td>Based on the provided financial data, we can c...</td>\n",
       "      <td>[Apple Inc. | 2022 Form 10-K | 44\\n\\n2021\\n\\n1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>In what areas did Apple see significant growth...</td>\n",
       "      <td>According to the provided context from Apple's...</td>\n",
       "      <td>[1. Results:\\n          1. Set new all-time re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How much was Apple's dividend per share for 20...</td>\n",
       "      <td>The answer is not explicitly stated in the pro...</td>\n",
       "      <td>[During 2021, aspects of the Company’s busines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What is Apple's total revenue for 2023 compare...   \n",
       "1   What percentage increase in Services revenue d...   \n",
       "2   How much has Apple's gross margin increased/de...   \n",
       "3   What was Apple's operating cash flow for 2023,...   \n",
       "4   In what sectors did Apple see significant grow...   \n",
       "5   By what percentage did Apple's iPhone revenue ...   \n",
       "6   What was Apple's research and development expe...   \n",
       "7   How has Apple's capital expenditures changed o...   \n",
       "8   In what regions did Apple see significant grow...   \n",
       "9   By what percentage did Apple's China revenue i...   \n",
       "10  What was Apple's effective tax rate for 2023, ...   \n",
       "11  How much has Apple's net income increased/decr...   \n",
       "12  What is Apple's total debt as of 2023, and how...   \n",
       "13  In what areas did Apple see significant growth...   \n",
       "14  How much was Apple's dividend per share for 20...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   According to the provided context from financi...   \n",
       "1   According to the text:\\n\\n\"Services net sales ...   \n",
       "2   Based on the provided financial data, we can c...   \n",
       "3   I'm happy to help! However, I need to point ou...   \n",
       "4   Based on the context from the financial 10K fi...   \n",
       "5   The provided context does not contain specific...   \n",
       "6   I'm happy to help! However, I need to clarify ...   \n",
       "7   The context provided does not mention anything...   \n",
       "8   According to the context, Apple saw significan...   \n",
       "9   The answer is not explicitly mentioned in the ...   \n",
       "10  Based on the provided context, there is no men...   \n",
       "11  Based on the provided financial data, we can c...   \n",
       "12  Based on the provided financial data, we can c...   \n",
       "13  According to the provided context from Apple's...   \n",
       "14  The answer is not explicitly stated in the pro...   \n",
       "\n",
       "                                             contexts  faithfulness  \\\n",
       "0   [The Company evaluates the performance of its ...           NaN   \n",
       "1   [(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n...           NaN   \n",
       "2   [Japan\\n\\nJapan net sales decreased during 202...           NaN   \n",
       "3   [Beginning balances\\n\\nCommon stock issued Com...           NaN   \n",
       "4   [1. Highlights:\\n          1. Revenue $58b.\\n ...           NaN   \n",
       "5   [1. Highlights:\\n          1. In uncertain env...           NaN   \n",
       "6   [(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n...           NaN   \n",
       "7   [Japan\\n\\nJapan net sales decreased during 202...           NaN   \n",
       "8   [1. Highlights:\\n          1. Best June qtr. r...           NaN   \n",
       "9   [1. Highlights:\\n          1. Dec. qtr. revenu...           NaN   \n",
       "10  [(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n...           NaN   \n",
       "11  [See accompanying Notes to Consolidated Financ...           NaN   \n",
       "12  [Apple Inc. | 2022 Form 10-K | 44\\n\\n2021\\n\\n1...           NaN   \n",
       "13  [1. Results:\\n          1. Set new all-time re...           NaN   \n",
       "14  [During 2021, aspects of the Company’s busines...           NaN   \n",
       "\n",
       "    answer_relevancy  context_relevancy  \n",
       "0                NaN           0.035503  \n",
       "1                NaN           0.019553  \n",
       "2                NaN           0.010610  \n",
       "3                NaN           0.015217  \n",
       "4                NaN           0.019704  \n",
       "5                NaN           0.014337  \n",
       "6                NaN           0.014768  \n",
       "7                NaN           0.011461  \n",
       "8                NaN           0.013699  \n",
       "9                NaN           0.053719  \n",
       "10               NaN           0.024768  \n",
       "11               NaN           0.008929  \n",
       "12               NaN           0.010417  \n",
       "13               NaN           0.016234  \n",
       "14               NaN           0.017857  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "This method helped us increase our faithfulness slightly but decreased our answer_relevancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for speed sake the propositions have been precomputed but you can generate them with the following function\n",
    "with open(\"propositions.json\", \"r\") as f:\n",
    "    preloaded_propositions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n* United States Securities and Exchange Commission is a regulatory agency.\\n* The commission is located in Washington, D.C. and has an address of 20549.\\n* Apple Inc. is a company that filed this report with the SEC.\\n* The company is registered under the name \"Apple Inc.\" and is incorporated in California (State or other jurisdiction of incorporation or organization).\\n* The company\\'s I.R.S. Employer Identification Number is 94-2404110.\\n* The company\\'s principal executive offices are located at One Apple Park Way, Cupertino, California with a zip code of 95014 and a telephone number including area code as (408) 996-1010.\\n* Securities registered pursuant to Section 12(b) of the Act include common stock with a par value per share of $0.00001 and various notes with different interest rates and maturity dates.\\n* The trading symbol for these securities is AAPL, which is listed on The Nasdaq Stock Market LLC.\\n* Apple Inc. is not required to file reports pursuant to Section 13 or Section 15(d) of the Act.\\n\\nNote: I\\'ve followed the rules provided to decompose the raw content into clear and simple propositions. Let me know if you need any further assistance!'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preloaded_propositions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549\\n\\nFORM 10-K\\n\\n(Mark One)\\n\\n☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the fiscal year ended September 25, 2021 or ☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\n\\nFor the transition period from to .\\n\\nCommission File Number: 001-36743\\n\\nApple Inc.\\n\\n(Exact name of Registrant as specified in its charter)\\n\\nCalifornia (State or other jurisdiction of incorporation or organization)\\n\\n94-2404110 (I.R.S. Employer Identification No.)\\n\\nOne Apple Park Way Cupertino, California (Address of principal executive offices)\\n\\n95014 (Zip Code)\\n\\n(408) 996-1010 (Registrant’s telephone number, including area code)\\n\\nSecurities registered pursuant to Section 12(b) of the Act:\\n\\nTitle of each class Common Stock, $0.00001 par value per share\\n\\n1.000% Notes due 2022 1.375% Notes due 2024 0.000% Notes due 2025 0.875% Notes due 2025 1.625% Notes due 2026 2.000% Notes due 2027 1.375% Notes due 2029 3.050% Notes due 2029 0.500% Notes due 2031 3.600% Notes due 2042\\n\\nTrading symbol(s) AAPL — — — — — — — — — —\\n\\nName of each exchange on which registered The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC The Nasdaq Stock Market LLC\\n\\nSecurities registered pursuant to Section 12(g) of the Act: None\\n\\nIndicate by check mark if the Registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.\\n\\nYes ☒ No ☐\\n\\nIndicate by check mark if the Registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act.\\n\\nYes ☐ No ☒\\n\\nIndicate by check mark whether the Registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the Registrant was required to file such reports), and (2) has been subject to\\n\\nsuch filing requirements for the past 90 days.\\n\\nYes ☒ No ☐'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def create_dense_props(chunk):\n",
    "    \"\"\"Create dense representation of raw text content.\"\"\"\n",
    "\n",
    "    preamble = \"\"\"\n",
    "        You are a helpful PDF extractor tool. You will be presented with segments from\n",
    "        raw documents composed of information about public companies.\n",
    "\n",
    "        Decompose and summarize the raw content into clear and simple propositions,\n",
    "        ensuring they are interpretable out of context. Consider the following rules:\n",
    "        1. Split compound sentences into simpler dense phrases that retain existing\n",
    "        meaning.\n",
    "        2. Simplify technical jargon or wording if possible while retaining existing\n",
    "        meaning.\n",
    "        2. For any named entity that is accompanied by additional descriptive information,\n",
    "        separate this information into its own distinct proposition.\n",
    "        3. Decontextualize the proposition by adding necessary modifier to nouns or\n",
    "        entire sentences and replacing pronouns (e.g., \"it\", \"he\", \"she\", \"they\", \"this\", \"that\")\n",
    "        with the full name of the entities they refer to.\n",
    "        4. Respond in the format content: results where results is the raw decomposed content.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        {preamble}\n",
    "        Decompose this raw content using the rules above: {flattened_chunks[0].page_content}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        return llm.generate([prompt]).generations[0][0].text\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse propositions attempt wait and backoff\", str(e), flush=True)\n",
    "        time.sleep(10)\n",
    "        # Retry\n",
    "        return create_dense_props(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if creating from scratch\n",
    "# propositions = [create_dense_props(chunk) for chunk in flattened_chunks]\n",
    "# with open(\"propositions.json\", \"w\") as f:\n",
    "#     json.dump(propositions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "prop_docs = [Document(page_content=prop, metadata={\"source\": \"local\"}) for prop in preloaded_propositions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed the props and store them in a new index as vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`index_schema` does not match generated metadata schema.\n",
      "If you meant to manually override the schema, please ignore this message.\n",
      "index_schema: {'vector': [{'name': 'prop_vector', 'algorithm': 'HNSW', 'dims': 384, 'distance_metric': 'COSINE', 'datatype': 'FLOAT32'}], 'text': [{'name': 'content'}], 'content_vector_key': 'prop_vector'}\n",
      "generated_schema: {'text': [{'name': 'source'}], 'numeric': [], 'tag': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.redis import Redis\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# set the index name for this example\n",
    "index_name = \"proposition_index\"\n",
    "\n",
    "# with langchain we can manually modify the default vector schema configuration\n",
    "vector_schema = {\n",
    "    \"name\": \"prop_vector\",        # name of the vector field in langchain\n",
    "    \"algorithm\": \"HNSW\",           # could use HNSW instead\n",
    "    \"dims\": 384,                   # set based on the HF model embedding dimension\n",
    "    \"distance_metric\": \"COSINE\",   # could use EUCLIDEAN or IP\n",
    "    \"datatype\": \"FLOAT32\",\n",
    "}\n",
    "\n",
    "# here we can define the entire schema spec for our index in LangChain\n",
    "index_schema = {\n",
    "    \"vector\": [vector_schema],\n",
    "    \"text\": [{\"name\": \"content\"}],\n",
    "    \"content_vector_key\": \"prop_vector\"    # name of the vector field in langchain\n",
    "}\n",
    "\n",
    "\n",
    "# construct the vector store class from texts and metadata\n",
    "prop_rds = Redis.from_documents(\n",
    "    documents=prop_docs,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    "    redis_url=REDIS_URL,\n",
    "    index_schema=index_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RAG chain but use prop index instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=prop_rds.as_retriever(search_type=\"similarity_distance_threshold\",search_kwargs={\"distance_threshold\":0.5}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    #verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What is Apple's total revenue for 2023 compared to the previous year?\",\n",
       " 'result': \"Question: What is Apple's total revenue for 2023 compared to the previous year?\\nAnswer: I don't know\\nSource: The provided context does not include financial data or information about Apple's revenue for 2023. The annual report (FORM 10-K) only provides information up to September 25, 2021, and does not include data for subsequent years.\",\n",
       " 'source_documents': [Document(page_content=\"Results\\n\\nThe following are the decomposed and summarized propositions from the raw content:\\n\\n1. The UNITED STATES SECURITIES AND EXCHANGE COMMISSION is a regulatory agency responsible for overseeing public companies.\\n2. Apple Inc. is a public company that has filed an annual report (FORM 10-K) with the SEC.\\n3. Apple's fiscal year ended on September 25, 2021.\\n4. Apple is headquartered in California and can be reached at (408) 996-1010.\\n5. The company's common stock has a par value of $0.00001 per share.\\n6. Apple has issued various types of notes with different interest rates and maturity dates:\\n\\t* 1.000% Notes due 2022\\n\\t* 1.375% Notes due 2024\\n\\t* 0.000% Notes due 2025\\n\\t* 0.875% Notes due 2025\\n\\t* 1.625% Notes due 2026\\n\\t* 2.000% Notes due 2027\\n\\t* 1.375% Notes due 2029\\n\\t* 3.050% Notes due 2029\\n\\t* 0.500% Notes due 2031\\n\\t* 3.600% Notes due 2042\\n7. Apple's trading symbol is AAPL, and its securities are registered on The Nasdaq Stock Market LLC.\\n8. The company is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.\\n\\nNote: All pronouns have been replaced with full names of entities, and necessary modifiers have been added to nouns or entire sentences.\", metadata={'id': 'doc:proposition_index:def1c08399fc4525b952cc1f269e33e6'}),\n",
       "  Document(page_content='UNITED STATES SECURITIES AND EXCHANGE COMMISSION, Washington, D.C., 20549; FORM 10-K, annual report for Apple Inc.', metadata={'id': 'doc:proposition_index:a7095c7ef5004c9cadc9cf1ea183bc92'}),\n",
       "  Document(page_content='Apple Inc., a company incorporated in California, filed its annual report with the United States Securities and Exchange Commission. The report is for the fiscal year ended September 25, 2021.\\n\\nresults:\\n\\n* Company: Apple Inc.\\n* Jurisdiction of incorporation or organization: California\\n* Employer Identification Number: 94-2404110\\n* Address of principal executive offices: One Apple Park Way Cupertino, California 95014\\n* Telephone number: (408) 996-1010\\n\\nSecurities registered:\\n\\n* Common Stock, $0.00001 par value per share\\n* Various notes with different due dates and interest rates:\\n\\t+ 1.000% Notes due 2022\\n\\t+ 1.375% Notes due 2024\\n\\t+ ...and so on until...\\n\\t+ 3.600% Notes due 2042\\n\\nExchanges: The Nasdaq Stock Market LLC', metadata={'id': 'doc:proposition_index:3b041e66c460411d906a6acd5ada1579'}),\n",
       "  Document(page_content=\"United States Securities and Exchange Commission, Washington, D.C. 20549.\\nresults:\\n• The US Securities and Exchange Commission is responsible for overseeing securities-related activities in the country.\\n• Apple Inc., a publicly traded company, has filed its annual report (Form 10-K) with the SEC.\\n• The report covers the company's financial performance for the fiscal year ended September 25, 2021.\", metadata={'id': 'doc:proposition_index:a45772e046e84e68b9bde6290c58c413'})]}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_qa(\"What is Apple's total revenue for 2023 compared to the previous year?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd86ca0bf054c8f83aadb48e12c6a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop_rag_test = evaluate_chain(prop_qa, questions, \"prop_rag_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.510476</td>\n",
       "      <td>0.333314</td>\n",
       "      <td>0.030353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.451568</td>\n",
       "      <td>0.487921</td>\n",
       "      <td>0.036376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.031676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy  context_relevancy\n",
       "count     15.000000         15.000000          15.000000\n",
       "mean       0.510476          0.333314           0.030353\n",
       "std        0.451568          0.487921           0.036376\n",
       "min        0.000000          0.000000           0.000000\n",
       "25%        0.000000          0.000000           0.008475\n",
       "50%        0.666667          0.000000           0.022222\n",
       "75%        0.928571          0.999852           0.031676\n",
       "max        1.000000          1.000000           0.142857"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_rag_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and conclusion\n",
    "\n",
    "\n",
    "As a review, in this notebook we covered:\n",
    "- why it's important to have an evaluation framework\n",
    "- the basic theory of RAGAS\n",
    "- how to interpret and generate faithfulness, answer_relevancy, and context_relevancy\n",
    "- code to evaluate two different RAG chains to monitor how creating dense props might improve our results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
